{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce544786-7477-49fb-a436-3a1e472d29ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/15/24 10:26:49] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> To use the Graphein submodule                                         <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/features/sequence/embeddings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">embeddings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/features/sequence/embeddings.py#45\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         graphein.protein.features.sequence.embeddings, you need to install:   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         biovec                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To do so, use the following command: pip install biovec               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Alternatively, you can install graphein with the extras:              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pip install graphein<span style=\"font-weight: bold\">[</span>extras<span style=\"font-weight: bold\">]</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/15/24 10:26:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m To use the Graphein submodule                                         \u001b]8;id=770386;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/features/sequence/embeddings.py\u001b\\\u001b[2membeddings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=551974;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/features/sequence/embeddings.py#45\u001b\\\u001b[2m45\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         graphein.protein.features.sequence.embeddings, you need to install:   \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         biovec                                                                \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To do so, use the following command: pip install biovec               \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Alternatively, you can install graphein with the extras:              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                               \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         pip install graphein\u001b[1m[\u001b[0mextras\u001b[1m]\u001b[0m                                          \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/15/24 10:26:50] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> To use the Graphein submodule graphein.protein.visualisation, you  <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/visualisation.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">visualisation.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/visualisation.py#36\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         need to install: pytorch3d                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pytorch3d cannot be installed via pip                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/15/24 10:26:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m To use the Graphein submodule graphein.protein.visualisation, you  \u001b]8;id=52753;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/visualisation.py\u001b\\\u001b[2mvisualisation.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=931200;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/visualisation.py#36\u001b\\\u001b[2m36\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         need to install: pytorch3d                                         \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         pytorch3d cannot be installed via pip                              \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> To use the Graphein submodule graphein.protein.meshes, you need to        <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/meshes.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">meshes.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/meshes.py#30\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         install: pytorch3d                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To do so, use the following command: pip install pytorch3d                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m To use the Graphein submodule graphein.protein.meshes, you need to        \u001b]8;id=939219;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/meshes.py\u001b\\\u001b[2mmeshes.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=457971;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/meshes.py#30\u001b\\\u001b[2m30\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         install: pytorch3d                                                        \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To do so, use the following command: pip install pytorch3d                \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphein.protein.config import ProteinGraphConfig\n",
    "from graphein.protein.graphs import construct_graph\n",
    "from graphein.protein.edges.distance import (add_peptide_bonds,\n",
    "                                             add_hydrogen_bond_interactions,\n",
    "                                             add_disulfide_interactions,\n",
    "                                             add_ionic_interactions,\n",
    "                                             add_aromatic_interactions,\n",
    "                                             add_aromatic_sulphur_interactions,\n",
    "                                             add_cation_pi_interactions\n",
    "                                            )\n",
    "from graphein.protein.features.nodes import (\n",
    "    amino_acid_one_hot,\n",
    "    expasy_protein_scale,\n",
    "    hydrogen_bond_acceptor,\n",
    "    hydrogen_bond_donor,\n",
    "    meiler_embedding\n",
    ")\n",
    "from graphein.protein.features.nodes.geometry import add_sidechain_vector, add_beta_carbon_vector, add_sequence_neighbour_vector\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "import h5py\n",
    "import g2papi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336d7703-50ba-49a2-ab6c-1fba8143da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038466b3-2344-4e45-a66c-a7597f8992e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_db_path = \"/work/gr-fe/databases/alpha_fold/human/\"\n",
    "prefix = \"AF-\"\n",
    "suffix = \"-F1-model_v4.pdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3efca5-479a-4d44-b26b-a340bef70b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define edge and annotation functions\n",
    "\n",
    "edge_funcs = {\"edge_construction_functions\": [add_peptide_bonds,\n",
    "                                              add_aromatic_interactions,\n",
    "                                              add_hydrogen_bond_interactions,\n",
    "                                              add_disulfide_interactions,\n",
    "                                              add_ionic_interactions,\n",
    "                                              add_aromatic_sulphur_interactions,\n",
    "                                              add_cation_pi_interactions]}\n",
    "\n",
    "\n",
    "all_node_metadata = {\"node_metadata_functions\" : [amino_acid_one_hot,\n",
    "                                                 expasy_protein_scale,\n",
    "                                                 hydrogen_bond_acceptor,\n",
    "                                                 hydrogen_bond_donor,\n",
    "                                                 meiler_embedding]}\n",
    "\n",
    "#all_graph_metadata = {\"graph_metadata_functions\": [esm_residue_embedding]}  \n",
    "\n",
    "#config = ProteinGraphConfig(**{**edge_funcs, **all_node_metadata, **all_graph_metadata}) \n",
    "config = ProteinGraphConfig(**{**edge_funcs, **all_node_metadata}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48cf6d15-d039-42d4-9039-d683e1d98ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HGNC</th>\n",
       "      <th>DN</th>\n",
       "      <th>LOF</th>\n",
       "      <th>GOF</th>\n",
       "      <th>UniprotEntry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARS1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P49588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCA1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O95477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q96AP0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACTA1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P68133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>P60709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>ZFPM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Q8WW38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>ZIC2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>O95409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>ZMYM2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9UBW7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>ZMYND11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Q15326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>ZNF462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Q96JM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HGNC  DN  LOF  GOF UniprotEntry\n",
       "0       AARS1   1    0    0       P49588\n",
       "1       ABCA1   1    0    0       O95477\n",
       "2         ACD   1    0    0       Q96AP0\n",
       "3       ACTA1   1    0    0       P68133\n",
       "4        ACTB   1    1    1       P60709\n",
       "...       ...  ..  ...  ...          ...\n",
       "1271    ZFPM2   0    1    0       Q8WW38\n",
       "1272     ZIC2   0    1    0       O95409\n",
       "1273    ZMYM2   0    1    0       Q9UBW7\n",
       "1274  ZMYND11   0    1    0       Q15326\n",
       "1275   ZNF462   0    1    0       Q96JM2\n",
       "\n",
       "[1276 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read ground_truth dataframe\n",
    "\n",
    "df = pd.read_csv(\"../data/DN_LOF_GOF_truth.tsv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4a8379-d3e4-4591-b3ec-de48313d03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels and uniprot ids\n",
    "\n",
    "all_uniprot_ids = [] \n",
    "all_hgnc = []\n",
    "all_labels = [] \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    all_uniprot_ids.append(row[\"UniprotEntry\"])\n",
    "    all_hgnc.append(row[\"HGNC\"])\n",
    "    all_labels.append([row[\"DN\"], row[\"LOF\"], row[\"GOF\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313c7fdd-8240-4375-81d6-b6c85b21b2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniprotEntry</th>\n",
       "      <th>ASAquick_normscore</th>\n",
       "      <th>DFLpredScore</th>\n",
       "      <th>DRNApredDNAscore</th>\n",
       "      <th>DRNApredRNAscore</th>\n",
       "      <th>DisoDNAscore</th>\n",
       "      <th>DisoPROscore</th>\n",
       "      <th>DisoRNAscore</th>\n",
       "      <th>MMseq2_conservation_score</th>\n",
       "      <th>MoRFchibiScore</th>\n",
       "      <th>PSIPRED_helix</th>\n",
       "      <th>PSIPRED_strand</th>\n",
       "      <th>SCRIBERscore</th>\n",
       "      <th>SignalP_score</th>\n",
       "      <th>flDPnn_score</th>\n",
       "      <th>seqlength</th>\n",
       "      <th>PTMbinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A024R1R8</td>\n",
       "      <td>0.747,0.578,0.611,0.572,0.581,0.494,0.366,0.52...</td>\n",
       "      <td>0.026,0.021,0.022,0.020,0.018,0.019,0.023,0.02...</td>\n",
       "      <td>0.036,0.092,0.094,0.123,0.070,0.081,0.080,0.09...</td>\n",
       "      <td>0.441,0.247,0.219,0.259,0.200,0.280,0.291,0.30...</td>\n",
       "      <td>0.478,0.444,0.516,0.472,0.430,0.489,0.541,0.50...</td>\n",
       "      <td>0.582,0.621,0.632,0.638,0.652,0.622,0.609,0.61...</td>\n",
       "      <td>0.034,0.029,0.024,0.024,0.024,0.024,0.023,0.01...</td>\n",
       "      <td>3.69,2.85,2.55,2.69,2.60,2.57,2.57,2.76,2.52,2...</td>\n",
       "      <td>0.835,0.839,0.848,0.862,0.859,0.859,0.871,0.89...</td>\n",
       "      <td>0,8,28,32,41,46,59,78,73,92,78,50,60,20,61,93,...</td>\n",
       "      <td>0,1,1,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>0.949,0.884,0.764,0.823,0.763,0.447,0.292,0.25...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.96,0.94,0.93,0.92,0.89,0.89,0.93,0.90,0.84,0...</td>\n",
       "      <td>64</td>\n",
       "      <td>0,1,1,0,0,0,0,5,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A024RBG1</td>\n",
       "      <td>0.695,0.392,0.521,0.209,0.444,0.421,0.455,0.40...</td>\n",
       "      <td>0.024,0.032,0.040,0.038,0.043,0.055,0.059,0.07...</td>\n",
       "      <td>0.099,0.090,0.134,0.082,0.236,0.132,0.199,0.36...</td>\n",
       "      <td>0.081,0.078,0.067,0.048,0.060,0.059,0.057,0.06...</td>\n",
       "      <td>0.172,0.142,0.135,0.145,0.110,0.116,0.094,0.12...</td>\n",
       "      <td>0.505,0.495,0.473,0.483,0.483,0.486,0.484,0.49...</td>\n",
       "      <td>0.060,0.057,0.055,0.053,0.056,0.048,0.046,0.05...</td>\n",
       "      <td>3.69,3.68,2.81,2.84,2.81,3.23,3.09,3.37,2.97,2...</td>\n",
       "      <td>0.653,0.663,0.677,0.673,0.675,0.673,0.669,0.66...</td>\n",
       "      <td>0,3,2,2,1,3,7,5,4,10,4,2,2,22,49,57,78,80,67,3...</td>\n",
       "      <td>0,4,7,8,3,3,3,7,19,24,39,27,9,4,1,1,2,4,11,32,...</td>\n",
       "      <td>0.278,0.234,0.214,0.239,0.288,0.276,0.251,0.29...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.35,0.38,0.42,0.46,0.45,0.45,0.45,0.42,0.38,0...</td>\n",
       "      <td>181</td>\n",
       "      <td>0,0,6,0,6,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A075B6H5</td>\n",
       "      <td>0.694,0.501,0.365,0.286,0.237,0.290,0.280,0.20...</td>\n",
       "      <td>0.068,0.082,0.084,0.107,0.138,0.158,0.191,0.22...</td>\n",
       "      <td>0.181,0.109,0.309,0.136,0.190,0.342,0.386,0.13...</td>\n",
       "      <td>0.052,0.044,0.032,0.030,0.031,0.034,0.034,0.03...</td>\n",
       "      <td>0.060,0.069,0.076,0.081,0.088,0.086,0.095,0.10...</td>\n",
       "      <td>0.481,0.501,0.490,0.473,0.473,0.476,0.468,0.42...</td>\n",
       "      <td>0.038,0.030,0.037,0.030,0.031,0.035,0.030,0.03...</td>\n",
       "      <td>3.68,2.88,2.96,2.74,2.61,2.96,2.96,2.19,3.23,2...</td>\n",
       "      <td>0.500,0.485,0.511,0.541,0.541,0.546,0.550,0.55...</td>\n",
       "      <td>0,1,1,2,3,3,2,3,4,10,16,7,1,2,3,70,77,95,94,94...</td>\n",
       "      <td>0,30,59,73,82,77,55,16,10,7,3,2,2,3,3,1,1,1,1,...</td>\n",
       "      <td>0.377,0.330,0.265,0.216,0.230,0.296,0.278,0.22...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.33,0.32,0.33,0.28,0.33,0.30,0.35,0.38,0.40,0...</td>\n",
       "      <td>130</td>\n",
       "      <td>0,0,2,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A075B6H7</td>\n",
       "      <td>0.721,0.579,0.358,0.389,0.238,0.276,0.085,0.08...</td>\n",
       "      <td>0.047,0.046,0.043,0.040,0.038,0.043,0.040,0.04...</td>\n",
       "      <td>0.152,0.203,0.157,0.115,0.130,0.130,0.099,0.09...</td>\n",
       "      <td>0.066,0.065,0.062,0.062,0.063,0.063,0.060,0.06...</td>\n",
       "      <td>0.072,0.077,0.081,0.048,0.052,0.053,0.054,0.05...</td>\n",
       "      <td>0.430,0.428,0.410,0.434,0.466,0.439,0.434,0.43...</td>\n",
       "      <td>0.042,0.027,0.018,0.022,0.020,0.024,0.023,0.01...</td>\n",
       "      <td>3.69,1.81,1.94,3.06,2.10,3.33,1.73,2.16,2.10,2...</td>\n",
       "      <td>0.546,0.539,0.545,0.549,0.559,0.571,0.587,0.58...</td>\n",
       "      <td>0,24,67,83,94,99,99,100,100,100,99,96,83,62,3,...</td>\n",
       "      <td>0,2,1,2,1,0,0,0,0,0,0,0,1,1,0,2,3,7,11,24,44,4...</td>\n",
       "      <td>0.146,0.148,0.107,0.170,0.141,0.178,0.136,0.17...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.14,0.13,0.12,0.07,0.10,0.07,0.08,0.08,0.11,0...</td>\n",
       "      <td>116</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A075B6H8</td>\n",
       "      <td>0.649,0.510,0.364,0.481,0.218,0.241,0.259,0.37...</td>\n",
       "      <td>0.060,0.054,0.067,0.061,0.056,0.052,0.048,0.05...</td>\n",
       "      <td>0.431,0.393,0.548,0.570,0.354,0.274,0.292,0.26...</td>\n",
       "      <td>0.038,0.038,0.040,0.037,0.036,0.036,0.036,0.03...</td>\n",
       "      <td>0.174,0.172,0.171,0.169,0.168,0.105,0.107,0.10...</td>\n",
       "      <td>0.252,0.282,0.286,0.287,0.311,0.357,0.381,0.35...</td>\n",
       "      <td>0.105,0.088,0.059,0.047,0.048,0.056,0.047,0.05...</td>\n",
       "      <td>3.68,2.92,3.67,2.93,1.84,3.23,2.11,3.35,2.04,2...</td>\n",
       "      <td>0.459,0.468,0.512,0.522,0.529,0.530,0.536,0.53...</td>\n",
       "      <td>0,10,29,48,82,91,97,99,99,99,99,100,99,99,95,8...</td>\n",
       "      <td>0,1,3,3,1,1,0,0,0,0,0,0,0,0,0,1,1,4,5,12,36,71...</td>\n",
       "      <td>0.395,0.278,0.208,0.353,0.186,0.211,0.164,0.25...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.26,0.17,0.18,0.13,0.12,0.07,0.09,0.09,0.09,0...</td>\n",
       "      <td>117</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20449</th>\n",
       "      <td>V9GZ13</td>\n",
       "      <td>0.752,0.627,0.587,0.419,0.434,0.395,0.326,0.47...</td>\n",
       "      <td>0.070,0.089,0.095,0.084,0.076,0.080,0.081,0.09...</td>\n",
       "      <td>0.818,0.894,0.837,0.867,0.869,0.882,0.437,0.88...</td>\n",
       "      <td>0.020,0.020,0.020,0.020,0.020,0.020,0.020,0.02...</td>\n",
       "      <td>0.054,0.059,0.064,0.069,0.074,0.080,0.081,0.09...</td>\n",
       "      <td>0.147,0.147,0.172,0.176,0.182,0.171,0.170,0.17...</td>\n",
       "      <td>0.052,0.057,0.056,0.061,0.047,0.044,0.041,0.04...</td>\n",
       "      <td>3.68,2.83,3.16,3.36,2.84,4.34,1.60,2.95,2.30,3...</td>\n",
       "      <td>0.860,0.890,0.901,0.982,0.981,0.981,0.981,0.98...</td>\n",
       "      <td>0,4,15,31,63,80,83,83,87,75,70,65,80,80,64,70,...</td>\n",
       "      <td>0,2,3,4,2,2,2,2,1,2,9,25,13,8,12,10,8,13,37,24...</td>\n",
       "      <td>0.873,0.716,0.745,0.722,0.672,0.855,0.643,0.76...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.41,0.44,0.45,0.41,0.32,0.19,0.12,0.13,0.13,0...</td>\n",
       "      <td>50</td>\n",
       "      <td>0,6,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20450</th>\n",
       "      <td>W5XKT8</td>\n",
       "      <td>0.590,0.263,0.221,0.247,0.248,0.137,0.144,0.32...</td>\n",
       "      <td>0.045,0.050,0.062,0.074,0.075,0.068,0.062,0.06...</td>\n",
       "      <td>0.119,0.088,0.078,0.082,0.103,0.097,0.119,0.32...</td>\n",
       "      <td>0.066,0.051,0.049,0.049,0.051,0.050,0.050,0.05...</td>\n",
       "      <td>0.185,0.199,0.198,0.195,0.192,0.191,0.189,0.18...</td>\n",
       "      <td>0.259,0.224,0.224,0.269,0.271,0.258,0.261,0.25...</td>\n",
       "      <td>0.302,0.303,0.292,0.298,0.214,0.161,0.166,0.14...</td>\n",
       "      <td>3.68,2.56,2.34,1.76,2.37,2.60,2.24,2.60,1.59,2...</td>\n",
       "      <td>0.530,0.534,0.533,0.525,0.515,0.505,0.454,0.42...</td>\n",
       "      <td>0,83,91,95,98,96,81,54,74,64,87,98,99,99,100,9...</td>\n",
       "      <td>0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>0.193,0.137,0.173,0.192,0.117,0.175,0.151,0.16...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.15,0.16,0.14,0.14,0.14,0.13,0.12,0.11,0.11,0...</td>\n",
       "      <td>324</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20451</th>\n",
       "      <td>W6CW81</td>\n",
       "      <td>0.703,0.524,0.455,0.454,0.260,0.369,0.272,0.16...</td>\n",
       "      <td>0.025,0.027,0.027,0.034,0.043,0.041,0.044,0.05...</td>\n",
       "      <td>0.257,0.144,0.442,0.246,0.349,0.418,0.124,0.11...</td>\n",
       "      <td>0.058,0.044,0.050,0.046,0.049,0.050,0.043,0.04...</td>\n",
       "      <td>0.156,0.144,0.158,0.158,0.150,0.122,0.121,0.11...</td>\n",
       "      <td>0.315,0.311,0.310,0.331,0.356,0.355,0.340,0.34...</td>\n",
       "      <td>0.022,0.026,0.017,0.018,0.019,0.021,0.018,0.01...</td>\n",
       "      <td>3.69,2.83,2.82,2.57,3.44,2.26,2.86,2.41,2.16,2...</td>\n",
       "      <td>0.548,0.555,0.586,0.602,0.602,0.611,0.618,0.62...</td>\n",
       "      <td>0,37,57,79,83,88,90,91,79,78,76,59,39,51,31,25...</td>\n",
       "      <td>0,0,1,2,2,2,3,7,14,7,13,17,12,5,3,2,1,0,0,0,0,...</td>\n",
       "      <td>0.247,0.219,0.167,0.181,0.205,0.161,0.161,0.15...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.41,0.36,0.32,0.20,0.26,0.26,0.19,0.19,0.15,0...</td>\n",
       "      <td>113</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20452</th>\n",
       "      <td>X5D2U9</td>\n",
       "      <td>0.570,0.295,0.150,0.142,0.357,0.109,0.425,0.51...</td>\n",
       "      <td>0.077,0.092,0.100,0.075,0.077,0.086,0.081,0.09...</td>\n",
       "      <td>0.077,0.072,0.071,0.066,0.143,0.080,0.097,0.12...</td>\n",
       "      <td>0.147,0.116,0.110,0.073,0.093,0.077,0.114,0.09...</td>\n",
       "      <td>0.301,0.305,0.295,0.286,0.275,0.253,0.247,0.23...</td>\n",
       "      <td>0.386,0.373,0.355,0.304,0.291,0.305,0.308,0.31...</td>\n",
       "      <td>0.048,0.050,0.058,0.068,0.048,0.055,0.042,0.05...</td>\n",
       "      <td>3.67,2.52,3.68,2.26,3.79,2.37,3.17,2.13,2.58,2...</td>\n",
       "      <td>0.535,0.551,0.561,0.566,0.566,0.560,0.523,0.44...</td>\n",
       "      <td>0,1,1,2,1,1,2,4,19,25,31,21,29,20,18,28,24,52,...</td>\n",
       "      <td>0,52,75,84,83,42,8,2,4,9,27,41,49,67,65,65,69,...</td>\n",
       "      <td>0.119,0.120,0.112,0.128,0.118,0.142,0.214,0.15...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.34,0.33,0.33,0.25,0.24,0.21,0.22,0.17,0.11,0...</td>\n",
       "      <td>266</td>\n",
       "      <td>0,0,8,0,6,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20453</th>\n",
       "      <td>X6R8D5</td>\n",
       "      <td>0.669,0.453,0.485,0.515,0.492,0.433,0.503,0.31...</td>\n",
       "      <td>0.053,0.062,0.062,0.070,0.058,0.045,0.048,0.05...</td>\n",
       "      <td>0.119,0.110,0.172,0.193,0.092,0.196,0.094,0.18...</td>\n",
       "      <td>0.068,0.064,0.063,0.065,0.058,0.064,0.058,0.06...</td>\n",
       "      <td>0.168,0.156,0.174,0.184,0.190,0.193,0.124,0.09...</td>\n",
       "      <td>0.739,0.758,0.766,0.752,0.783,0.777,0.776,0.77...</td>\n",
       "      <td>0.010,0.012,0.010,0.012,0.009,0.008,0.007,0.00...</td>\n",
       "      <td>2.36,2.11,2.95,2.26,2.70,3.53,2.70,1.87,3.22,1...</td>\n",
       "      <td>0.655,0.660,0.673,0.676,0.681,0.683,0.682,0.68...</td>\n",
       "      <td>0,2,9,13,20,14,6,1,2,1,1,2,4,9,9,3,3,23,23,28,...</td>\n",
       "      <td>0,2,3,6,6,4,3,1,1,1,1,2,6,9,5,3,4,3,3,2,2,1,1,...</td>\n",
       "      <td>0.824,0.652,0.828,0.768,0.767,0.817,0.766,0.73...</td>\n",
       "      <td>0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...</td>\n",
       "      <td>0.62,0.67,0.64,0.60,0.58,0.64,0.63,0.69,0.64,0...</td>\n",
       "      <td>127</td>\n",
       "      <td>0,0,0,6,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20454 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UniprotEntry                                 ASAquick_normscore  \\\n",
       "0       A0A024R1R8  0.747,0.578,0.611,0.572,0.581,0.494,0.366,0.52...   \n",
       "1       A0A024RBG1  0.695,0.392,0.521,0.209,0.444,0.421,0.455,0.40...   \n",
       "2       A0A075B6H5  0.694,0.501,0.365,0.286,0.237,0.290,0.280,0.20...   \n",
       "3       A0A075B6H7  0.721,0.579,0.358,0.389,0.238,0.276,0.085,0.08...   \n",
       "4       A0A075B6H8  0.649,0.510,0.364,0.481,0.218,0.241,0.259,0.37...   \n",
       "...            ...                                                ...   \n",
       "20449       V9GZ13  0.752,0.627,0.587,0.419,0.434,0.395,0.326,0.47...   \n",
       "20450       W5XKT8  0.590,0.263,0.221,0.247,0.248,0.137,0.144,0.32...   \n",
       "20451       W6CW81  0.703,0.524,0.455,0.454,0.260,0.369,0.272,0.16...   \n",
       "20452       X5D2U9  0.570,0.295,0.150,0.142,0.357,0.109,0.425,0.51...   \n",
       "20453       X6R8D5  0.669,0.453,0.485,0.515,0.492,0.433,0.503,0.31...   \n",
       "\n",
       "                                            DFLpredScore  \\\n",
       "0      0.026,0.021,0.022,0.020,0.018,0.019,0.023,0.02...   \n",
       "1      0.024,0.032,0.040,0.038,0.043,0.055,0.059,0.07...   \n",
       "2      0.068,0.082,0.084,0.107,0.138,0.158,0.191,0.22...   \n",
       "3      0.047,0.046,0.043,0.040,0.038,0.043,0.040,0.04...   \n",
       "4      0.060,0.054,0.067,0.061,0.056,0.052,0.048,0.05...   \n",
       "...                                                  ...   \n",
       "20449  0.070,0.089,0.095,0.084,0.076,0.080,0.081,0.09...   \n",
       "20450  0.045,0.050,0.062,0.074,0.075,0.068,0.062,0.06...   \n",
       "20451  0.025,0.027,0.027,0.034,0.043,0.041,0.044,0.05...   \n",
       "20452  0.077,0.092,0.100,0.075,0.077,0.086,0.081,0.09...   \n",
       "20453  0.053,0.062,0.062,0.070,0.058,0.045,0.048,0.05...   \n",
       "\n",
       "                                        DRNApredDNAscore  \\\n",
       "0      0.036,0.092,0.094,0.123,0.070,0.081,0.080,0.09...   \n",
       "1      0.099,0.090,0.134,0.082,0.236,0.132,0.199,0.36...   \n",
       "2      0.181,0.109,0.309,0.136,0.190,0.342,0.386,0.13...   \n",
       "3      0.152,0.203,0.157,0.115,0.130,0.130,0.099,0.09...   \n",
       "4      0.431,0.393,0.548,0.570,0.354,0.274,0.292,0.26...   \n",
       "...                                                  ...   \n",
       "20449  0.818,0.894,0.837,0.867,0.869,0.882,0.437,0.88...   \n",
       "20450  0.119,0.088,0.078,0.082,0.103,0.097,0.119,0.32...   \n",
       "20451  0.257,0.144,0.442,0.246,0.349,0.418,0.124,0.11...   \n",
       "20452  0.077,0.072,0.071,0.066,0.143,0.080,0.097,0.12...   \n",
       "20453  0.119,0.110,0.172,0.193,0.092,0.196,0.094,0.18...   \n",
       "\n",
       "                                        DRNApredRNAscore  \\\n",
       "0      0.441,0.247,0.219,0.259,0.200,0.280,0.291,0.30...   \n",
       "1      0.081,0.078,0.067,0.048,0.060,0.059,0.057,0.06...   \n",
       "2      0.052,0.044,0.032,0.030,0.031,0.034,0.034,0.03...   \n",
       "3      0.066,0.065,0.062,0.062,0.063,0.063,0.060,0.06...   \n",
       "4      0.038,0.038,0.040,0.037,0.036,0.036,0.036,0.03...   \n",
       "...                                                  ...   \n",
       "20449  0.020,0.020,0.020,0.020,0.020,0.020,0.020,0.02...   \n",
       "20450  0.066,0.051,0.049,0.049,0.051,0.050,0.050,0.05...   \n",
       "20451  0.058,0.044,0.050,0.046,0.049,0.050,0.043,0.04...   \n",
       "20452  0.147,0.116,0.110,0.073,0.093,0.077,0.114,0.09...   \n",
       "20453  0.068,0.064,0.063,0.065,0.058,0.064,0.058,0.06...   \n",
       "\n",
       "                                            DisoDNAscore  \\\n",
       "0      0.478,0.444,0.516,0.472,0.430,0.489,0.541,0.50...   \n",
       "1      0.172,0.142,0.135,0.145,0.110,0.116,0.094,0.12...   \n",
       "2      0.060,0.069,0.076,0.081,0.088,0.086,0.095,0.10...   \n",
       "3      0.072,0.077,0.081,0.048,0.052,0.053,0.054,0.05...   \n",
       "4      0.174,0.172,0.171,0.169,0.168,0.105,0.107,0.10...   \n",
       "...                                                  ...   \n",
       "20449  0.054,0.059,0.064,0.069,0.074,0.080,0.081,0.09...   \n",
       "20450  0.185,0.199,0.198,0.195,0.192,0.191,0.189,0.18...   \n",
       "20451  0.156,0.144,0.158,0.158,0.150,0.122,0.121,0.11...   \n",
       "20452  0.301,0.305,0.295,0.286,0.275,0.253,0.247,0.23...   \n",
       "20453  0.168,0.156,0.174,0.184,0.190,0.193,0.124,0.09...   \n",
       "\n",
       "                                            DisoPROscore  \\\n",
       "0      0.582,0.621,0.632,0.638,0.652,0.622,0.609,0.61...   \n",
       "1      0.505,0.495,0.473,0.483,0.483,0.486,0.484,0.49...   \n",
       "2      0.481,0.501,0.490,0.473,0.473,0.476,0.468,0.42...   \n",
       "3      0.430,0.428,0.410,0.434,0.466,0.439,0.434,0.43...   \n",
       "4      0.252,0.282,0.286,0.287,0.311,0.357,0.381,0.35...   \n",
       "...                                                  ...   \n",
       "20449  0.147,0.147,0.172,0.176,0.182,0.171,0.170,0.17...   \n",
       "20450  0.259,0.224,0.224,0.269,0.271,0.258,0.261,0.25...   \n",
       "20451  0.315,0.311,0.310,0.331,0.356,0.355,0.340,0.34...   \n",
       "20452  0.386,0.373,0.355,0.304,0.291,0.305,0.308,0.31...   \n",
       "20453  0.739,0.758,0.766,0.752,0.783,0.777,0.776,0.77...   \n",
       "\n",
       "                                            DisoRNAscore  \\\n",
       "0      0.034,0.029,0.024,0.024,0.024,0.024,0.023,0.01...   \n",
       "1      0.060,0.057,0.055,0.053,0.056,0.048,0.046,0.05...   \n",
       "2      0.038,0.030,0.037,0.030,0.031,0.035,0.030,0.03...   \n",
       "3      0.042,0.027,0.018,0.022,0.020,0.024,0.023,0.01...   \n",
       "4      0.105,0.088,0.059,0.047,0.048,0.056,0.047,0.05...   \n",
       "...                                                  ...   \n",
       "20449  0.052,0.057,0.056,0.061,0.047,0.044,0.041,0.04...   \n",
       "20450  0.302,0.303,0.292,0.298,0.214,0.161,0.166,0.14...   \n",
       "20451  0.022,0.026,0.017,0.018,0.019,0.021,0.018,0.01...   \n",
       "20452  0.048,0.050,0.058,0.068,0.048,0.055,0.042,0.05...   \n",
       "20453  0.010,0.012,0.010,0.012,0.009,0.008,0.007,0.00...   \n",
       "\n",
       "                               MMseq2_conservation_score  \\\n",
       "0      3.69,2.85,2.55,2.69,2.60,2.57,2.57,2.76,2.52,2...   \n",
       "1      3.69,3.68,2.81,2.84,2.81,3.23,3.09,3.37,2.97,2...   \n",
       "2      3.68,2.88,2.96,2.74,2.61,2.96,2.96,2.19,3.23,2...   \n",
       "3      3.69,1.81,1.94,3.06,2.10,3.33,1.73,2.16,2.10,2...   \n",
       "4      3.68,2.92,3.67,2.93,1.84,3.23,2.11,3.35,2.04,2...   \n",
       "...                                                  ...   \n",
       "20449  3.68,2.83,3.16,3.36,2.84,4.34,1.60,2.95,2.30,3...   \n",
       "20450  3.68,2.56,2.34,1.76,2.37,2.60,2.24,2.60,1.59,2...   \n",
       "20451  3.69,2.83,2.82,2.57,3.44,2.26,2.86,2.41,2.16,2...   \n",
       "20452  3.67,2.52,3.68,2.26,3.79,2.37,3.17,2.13,2.58,2...   \n",
       "20453  2.36,2.11,2.95,2.26,2.70,3.53,2.70,1.87,3.22,1...   \n",
       "\n",
       "                                          MoRFchibiScore  \\\n",
       "0      0.835,0.839,0.848,0.862,0.859,0.859,0.871,0.89...   \n",
       "1      0.653,0.663,0.677,0.673,0.675,0.673,0.669,0.66...   \n",
       "2      0.500,0.485,0.511,0.541,0.541,0.546,0.550,0.55...   \n",
       "3      0.546,0.539,0.545,0.549,0.559,0.571,0.587,0.58...   \n",
       "4      0.459,0.468,0.512,0.522,0.529,0.530,0.536,0.53...   \n",
       "...                                                  ...   \n",
       "20449  0.860,0.890,0.901,0.982,0.981,0.981,0.981,0.98...   \n",
       "20450  0.530,0.534,0.533,0.525,0.515,0.505,0.454,0.42...   \n",
       "20451  0.548,0.555,0.586,0.602,0.602,0.611,0.618,0.62...   \n",
       "20452  0.535,0.551,0.561,0.566,0.566,0.560,0.523,0.44...   \n",
       "20453  0.655,0.660,0.673,0.676,0.681,0.683,0.682,0.68...   \n",
       "\n",
       "                                           PSIPRED_helix  \\\n",
       "0      0,8,28,32,41,46,59,78,73,92,78,50,60,20,61,93,...   \n",
       "1      0,3,2,2,1,3,7,5,4,10,4,2,2,22,49,57,78,80,67,3...   \n",
       "2      0,1,1,2,3,3,2,3,4,10,16,7,1,2,3,70,77,95,94,94...   \n",
       "3      0,24,67,83,94,99,99,100,100,100,99,96,83,62,3,...   \n",
       "4      0,10,29,48,82,91,97,99,99,99,99,100,99,99,95,8...   \n",
       "...                                                  ...   \n",
       "20449  0,4,15,31,63,80,83,83,87,75,70,65,80,80,64,70,...   \n",
       "20450  0,83,91,95,98,96,81,54,74,64,87,98,99,99,100,9...   \n",
       "20451  0,37,57,79,83,88,90,91,79,78,76,59,39,51,31,25...   \n",
       "20452  0,1,1,2,1,1,2,4,19,25,31,21,29,20,18,28,24,52,...   \n",
       "20453  0,2,9,13,20,14,6,1,2,1,1,2,4,9,9,3,3,23,23,28,...   \n",
       "\n",
       "                                          PSIPRED_strand  \\\n",
       "0      0,1,1,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "1      0,4,7,8,3,3,3,7,19,24,39,27,9,4,1,1,2,4,11,32,...   \n",
       "2      0,30,59,73,82,77,55,16,10,7,3,2,2,3,3,1,1,1,1,...   \n",
       "3      0,2,1,2,1,0,0,0,0,0,0,0,1,1,0,2,3,7,11,24,44,4...   \n",
       "4      0,1,3,3,1,1,0,0,0,0,0,0,0,0,0,1,1,4,5,12,36,71...   \n",
       "...                                                  ...   \n",
       "20449  0,2,3,4,2,2,2,2,1,2,9,25,13,8,12,10,8,13,37,24...   \n",
       "20450  0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "20451  0,0,1,2,2,2,3,7,14,7,13,17,12,5,3,2,1,0,0,0,0,...   \n",
       "20452  0,52,75,84,83,42,8,2,4,9,27,41,49,67,65,65,69,...   \n",
       "20453  0,2,3,6,6,4,3,1,1,1,1,2,6,9,5,3,4,3,3,2,2,1,1,...   \n",
       "\n",
       "                                            SCRIBERscore  \\\n",
       "0      0.949,0.884,0.764,0.823,0.763,0.447,0.292,0.25...   \n",
       "1      0.278,0.234,0.214,0.239,0.288,0.276,0.251,0.29...   \n",
       "2      0.377,0.330,0.265,0.216,0.230,0.296,0.278,0.22...   \n",
       "3      0.146,0.148,0.107,0.170,0.141,0.178,0.136,0.17...   \n",
       "4      0.395,0.278,0.208,0.353,0.186,0.211,0.164,0.25...   \n",
       "...                                                  ...   \n",
       "20449  0.873,0.716,0.745,0.722,0.672,0.855,0.643,0.76...   \n",
       "20450  0.193,0.137,0.173,0.192,0.117,0.175,0.151,0.16...   \n",
       "20451  0.247,0.219,0.167,0.181,0.205,0.161,0.161,0.15...   \n",
       "20452  0.119,0.120,0.112,0.128,0.118,0.142,0.214,0.15...   \n",
       "20453  0.824,0.652,0.828,0.768,0.767,0.817,0.766,0.73...   \n",
       "\n",
       "                                           SignalP_score  \\\n",
       "0      0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "1      0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "2      0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "3      0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "4      0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "...                                                  ...   \n",
       "20449  0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "20450  0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "20451  0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "20452  0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "20453  0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.00...   \n",
       "\n",
       "                                            flDPnn_score  seqlength  \\\n",
       "0      0.96,0.94,0.93,0.92,0.89,0.89,0.93,0.90,0.84,0...         64   \n",
       "1      0.35,0.38,0.42,0.46,0.45,0.45,0.45,0.42,0.38,0...        181   \n",
       "2      0.33,0.32,0.33,0.28,0.33,0.30,0.35,0.38,0.40,0...        130   \n",
       "3      0.14,0.13,0.12,0.07,0.10,0.07,0.08,0.08,0.11,0...        116   \n",
       "4      0.26,0.17,0.18,0.13,0.12,0.07,0.09,0.09,0.09,0...        117   \n",
       "...                                                  ...        ...   \n",
       "20449  0.41,0.44,0.45,0.41,0.32,0.19,0.12,0.13,0.13,0...         50   \n",
       "20450  0.15,0.16,0.14,0.14,0.14,0.13,0.12,0.11,0.11,0...        324   \n",
       "20451  0.41,0.36,0.32,0.20,0.26,0.26,0.19,0.19,0.15,0...        113   \n",
       "20452  0.34,0.33,0.33,0.25,0.24,0.21,0.22,0.17,0.11,0...        266   \n",
       "20453  0.62,0.67,0.64,0.60,0.58,0.64,0.63,0.69,0.64,0...        127   \n",
       "\n",
       "                                               PTMbinary  \n",
       "0      0,1,1,0,0,0,0,5,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "1      0,0,6,0,6,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,...  \n",
       "2      0,0,2,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "3      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "4      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "...                                                  ...  \n",
       "20449  0,6,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "20450  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "20451  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,...  \n",
       "20452  0,0,8,0,6,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "20453  0,0,0,6,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,...  \n",
       "\n",
       "[20454 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read extra features from describeProt\n",
    "\n",
    "describe_prot = pd.read_csv(\"../data/describePROT_clean.tsv\", sep=\"\\t\")\n",
    "describe_prot_featnames = describe_prot.columns[(describe_prot.columns != \"seqlength\") & (describe_prot.columns != \"UniprotEntry\") & (describe_prot.columns != \"SignalP_score\")] #SignalP_score doesnt match the protein length\n",
    "describe_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6401c9-9e68-4116-b374-9be21923b52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Length</th>\n",
       "      <th>ACT_SITE</th>\n",
       "      <th>BINDING</th>\n",
       "      <th>DNA_BIND</th>\n",
       "      <th>TOPO_DOM</th>\n",
       "      <th>TRANSMEM</th>\n",
       "      <th>DISULFID</th>\n",
       "      <th>PROPEP</th>\n",
       "      <th>SIGNAL</th>\n",
       "      <th>TRANSIT</th>\n",
       "      <th>STRAND</th>\n",
       "      <th>HELIX</th>\n",
       "      <th>COILED</th>\n",
       "      <th>COMPBIAS</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>REGION</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>ZN_FING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A087X1C5</td>\n",
       "      <td>515</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1100000000000000000000011111111111111111111111...</td>\n",
       "      <td>0011111111111111111111100000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000001...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000011...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0B4J2F0</td>\n",
       "      <td>54</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111000000000000000000000111111111111111111111...</td>\n",
       "      <td>0000111111111111111111111000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111110000000000000000000000000...</td>\n",
       "      <td>1100000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000001111111111111111111111111111111111111000...</td>\n",
       "      <td>0000000000000000000000000011111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000011...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000011111110000000000...</td>\n",
       "      <td>0000000000000001000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0B4J2F2</td>\n",
       "      <td>783</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000011111111100000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000011111111100011111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000011111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>16</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>1111111111111111</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000011100000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "      <td>0000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0K2S4Q6</td>\n",
       "      <td>201</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000001111111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000001000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111110000000000000000000000...</td>\n",
       "      <td>1111111111111110000010000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000111111000011111110...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000001111111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20429</th>\n",
       "      <td>Q9UI54</td>\n",
       "      <td>55</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000001111111111...</td>\n",
       "      <td>0000000000000011111111111111111111100000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111111111111111100000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20430</th>\n",
       "      <td>Q9UI72</td>\n",
       "      <td>69</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "      <td>1111111111000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111100000000000000000000000...</td>\n",
       "      <td>1000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000111111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000111111111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20431</th>\n",
       "      <td>Q9Y3F1</td>\n",
       "      <td>56</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111000000000000000000000001111111111111111111...</td>\n",
       "      <td>0011001111111111111111111110000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000100010000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111100000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20432</th>\n",
       "      <td>Q9Y6C7</td>\n",
       "      <td>94</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0110000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000110011110011111111100111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111111110000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000010111111111111111111000000111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20433</th>\n",
       "      <td>Q9Y6Z2</td>\n",
       "      <td>57</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000010000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111100000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000011111100000111111111110000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111110001000101010000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20434 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Entry  Length                                           ACT_SITE  \\\n",
       "0      A0A087X1C5     515  0000000000000000000000000000000000000000000000...   \n",
       "1      A0A0B4J2F0      54  0000000000000000000000000000000000000000000000...   \n",
       "2      A0A0B4J2F2     783  0000000000000000000000000000000000000000000000...   \n",
       "3      A0A0C5B5G6      16                                   0000000000000000   \n",
       "4      A0A0K2S4Q6     201  0000000000000000000000000000000000000000000000...   \n",
       "...           ...     ...                                                ...   \n",
       "20429      Q9UI54      55  0000000000000000000000000000000000000000000000...   \n",
       "20430      Q9UI72      69  0000000000000000000000000000000000000000000000...   \n",
       "20431      Q9Y3F1      56  0000000000000000000000000000000000000000000000...   \n",
       "20432      Q9Y6C7      94  0000000000000000000000000000000000000000000000...   \n",
       "20433      Q9Y6Z2      57  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                 BINDING  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000000000000000000000000...   \n",
       "2      0000000000000000000000000000000011111111100000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                DNA_BIND  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000000000000000000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                TOPO_DOM  \\\n",
       "0      1100000000000000000000011111111111111111111111...   \n",
       "1      1111000000000000000000000111111111111111111111...   \n",
       "2      1111111111111111111111111111111111111111111111...   \n",
       "3                                       1111111111111111   \n",
       "4      0000000000000000000000001111111111111111111111...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000001111111111...   \n",
       "20430  1111111111111111111111111111111111111111111111...   \n",
       "20431  1111000000000000000000000001111111111111111111...   \n",
       "20432  0110000000000000000000000000000000000000000000...   \n",
       "20433  1111111111111111111111111111111111111111111111...   \n",
       "\n",
       "                                                TRANSMEM  \\\n",
       "0      0011111111111111111111100000000000000000000000...   \n",
       "1      0000111111111111111111111000000000000000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000011111111111111111111100000000000...   \n",
       "20430  1111111111000000000000000000000000000000000000...   \n",
       "20431  0011001111111111111111111110000000000000000000...   \n",
       "20432  0000000000110011110011111111100111111111111111...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                DISULFID  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000000000000000000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000001000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000100010000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000010000000000000...   \n",
       "\n",
       "                                                  PROPEP  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000000000000000000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                  SIGNAL  \\\n",
       "0      1111111111111111111111000000000000000000000000...   \n",
       "1      1111111111111111111110000000000000000000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      1111111111111111111111110000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  1111111111111111111111111111111111100000000000...   \n",
       "20430  1111111111111111111111100000000000000000000000...   \n",
       "20431  1111111111111111111100000000000000000000000000...   \n",
       "20432  1111111111111111111111111110000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                 TRANSIT  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      1100000000000000000000000000000000000000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      1111111111111110000010000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  1000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  1111111100000000000000000000000000000000000000...   \n",
       "\n",
       "                                                  STRAND  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000000000000000000000000...   \n",
       "2      0000000000000000000000000011111111100011111111...   \n",
       "3                                       0000000011100000   \n",
       "4      0000000000000000000000000000111111000011111110...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000011111100000111111111110000...   \n",
       "\n",
       "                                                   HELIX  \\\n",
       "0      0000000000000000000000000000000000000000000001...   \n",
       "1      0000001111111111111111111111111111111111111000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000010111111111111111111000000111111111111...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                  COILED  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000011111111111111111111...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                COMPBIAS  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000000000000000000000011...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000111111111111111111111...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                  DOMAIN  \\\n",
       "0      0000000000000000000000000000000000000000000011...   \n",
       "1      0000000000000000000000000000000000000000000000...   \n",
       "2      0000000000000000000000000011111111111111111111...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000001111111111111111111111...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                  REGION  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000000000000000000011111110000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000111111111111111111111111...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  1111110001000101010000000000000000000000000000...   \n",
       "\n",
       "                                                  REPEAT  \\\n",
       "0      0000000000000000000000000000000000000000000000...   \n",
       "1      0000000000000001000000000000000000000000000000...   \n",
       "2      0000000000000000000000000000000000000000000000...   \n",
       "3                                       0000000000000000   \n",
       "4      0000000000000000000000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "20429  0000000000000000000000000000000000000000000000...   \n",
       "20430  0000000000000000000000000000000000000000000000...   \n",
       "20431  0000000000000000000000000000000000000000000000...   \n",
       "20432  0000000000000000000000000000000000000000000000...   \n",
       "20433  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                 ZN_FING  \n",
       "0      0000000000000000000000000000000000000000000000...  \n",
       "1      0000000000000000000000000000000000000000000000...  \n",
       "2      0000000000000000000000000000000000000000000000...  \n",
       "3                                       0000000000000000  \n",
       "4      0000000000000000000000000000000000000000000000...  \n",
       "...                                                  ...  \n",
       "20429  0000000000000000000000000000000000000000000000...  \n",
       "20430  0000000000000000000000000000000000000000000000...  \n",
       "20431  0000000000000000000000000000000000000000000000...  \n",
       "20432  0000000000000000000000000000000000000000000000...  \n",
       "20433  0000000000000000000000000000000000000000000000...  \n",
       "\n",
       "[20434 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniprot = pd.read_csv(\"../data/uniprot_all_human_proteins_annotated.txt\", sep=\"\\t\")\n",
    "uniprot_features = ['ACT_SITE', 'BINDING', 'DNA_BIND',\n",
    "                   'TOPO_DOM', 'TRANSMEM',\n",
    "                   'DISULFID',  'PROPEP', 'SIGNAL', 'TRANSIT',\n",
    "                   'STRAND', 'HELIX',\n",
    "                   'COILED', 'COMPBIAS', 'DOMAIN', 'REGION', 'REPEAT', 'ZN_FING']\n",
    "\n",
    "# Initialize a new DataFrame to store the output\n",
    "uniprot_clean = pd.DataFrame()\n",
    "uniprot_clean['Entry'] = uniprot['Entry']  # Copy 'Entry' column Length\n",
    "uniprot_clean['Length'] = uniprot['Length'] \n",
    "\n",
    "# Iterate over each feature and assign the correct value to the output\n",
    "for feature in uniprot_features:\n",
    "    actual_or_pred_col = f'actual_or_pred_{feature}'\n",
    "    actual_annotation_col = f'annotation_actual_{feature}'\n",
    "    pred_annotation_col = f'annotation_pred_{feature}'\n",
    "    \n",
    "    # Use `np.where` to conditionally select the 'actual' or 'pred' annotation\n",
    "    uniprot_clean[feature] = uniprot.apply(\n",
    "        lambda row: row[actual_annotation_col] if row[actual_or_pred_col] == 'actual' else row[pred_annotation_col], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "uniprot_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b67f2037-a708-4ac9-899f-dd812f2de85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>phyloP100way_vertebrate</th>\n",
       "      <th>phyloP30way_mammalian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A075B759</td>\n",
       "      <td>1.6,0.1,1.2,1.4,-0.1,3.1,1.5,2.3,0.7,-0.4,-1.7...</td>\n",
       "      <td>0.3,0.3,-0.5,-1.5,-0.8,-0.3,-0.1,0,-0.1,-0.1,-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A075B767</td>\n",
       "      <td>1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1....</td>\n",
       "      <td>0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A087WTH1</td>\n",
       "      <td>3.1,2.4,2.8,1.8,4.1,2.7,2.2,1.8,2.3,0.3,1.9,1....</td>\n",
       "      <td>1.2,0.6,1.2,0.9,1.2,1.3,1.1,0.7,0.9,-0.1,1.1,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A087WUV0</td>\n",
       "      <td>0.6,0.8,-0.4,-0.9,0.5,0.6,2.5,-0.1,0.5,0.9,1.3...</td>\n",
       "      <td>0.9,0.7,0.8,-0.2,0.5,1,0.6,0,0.4,0.1,0.1,0.9,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A087WV53</td>\n",
       "      <td>3,2.3,3.1,0.9,1.7,0.6,0.1,2.1,2.1,0.2,-0.4,1,0...</td>\n",
       "      <td>1,0.9,0.7,0.9,0.9,0.9,0.1,0.8,0.7,0.5,0.3,0.5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18174</th>\n",
       "      <td>Q9Y6Z7</td>\n",
       "      <td>4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4....</td>\n",
       "      <td>1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18175</th>\n",
       "      <td>U3KPV4</td>\n",
       "      <td>3.7,2.2,2.9,0.6,2.7,2.7,0.1,-0.4,7.4,2.8,0.4,2...</td>\n",
       "      <td>0.3,0.8,1,0.7,1.1,1.1,-0.1,0.4,1.2,1.1,-0.1,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18176</th>\n",
       "      <td>W5XKT8</td>\n",
       "      <td>1.1,1.2,-0.2,-0.2,-0.6,-0.9,-1.9,-0.9,-0.2,0.3...</td>\n",
       "      <td>1.2,0.6,-0.2,-0.7,-0.3,-0.7,0.2,-0.4,-0.7,-0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18177</th>\n",
       "      <td>X6R8D5</td>\n",
       "      <td>-0.9,0.5,0.5,-0.3,1.2,-1.6,0.3,0.2,0.2,0.2,0,0...</td>\n",
       "      <td>0.3,-0.4,0.3,-0.2,0.8,-0.1,1.1,0.1,0.3,0.1,0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18178</th>\n",
       "      <td>X6R8R1</td>\n",
       "      <td>0,1.6,0.2,0.5,-1.8,1.6,4.9,1.9,3.6,6.9,0.7,2.3...</td>\n",
       "      <td>0.5,1.1,-0.5,-0.9,-0.9,0.4,1,0.3,0.4,1,0.1,0.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18179 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Entry                            phyloP100way_vertebrate  \\\n",
       "0      A0A075B759  1.6,0.1,1.2,1.4,-0.1,3.1,1.5,2.3,0.7,-0.4,-1.7...   \n",
       "1      A0A075B767  1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1.8,1....   \n",
       "2      A0A087WTH1  3.1,2.4,2.8,1.8,4.1,2.7,2.2,1.8,2.3,0.3,1.9,1....   \n",
       "3      A0A087WUV0  0.6,0.8,-0.4,-0.9,0.5,0.6,2.5,-0.1,0.5,0.9,1.3...   \n",
       "4      A0A087WV53  3,2.3,3.1,0.9,1.7,0.6,0.1,2.1,2.1,0.2,-0.4,1,0...   \n",
       "...           ...                                                ...   \n",
       "18174      Q9Y6Z7  4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4....   \n",
       "18175      U3KPV4  3.7,2.2,2.9,0.6,2.7,2.7,0.1,-0.4,7.4,2.8,0.4,2...   \n",
       "18176      W5XKT8  1.1,1.2,-0.2,-0.2,-0.6,-0.9,-1.9,-0.9,-0.2,0.3...   \n",
       "18177      X6R8D5  -0.9,0.5,0.5,-0.3,1.2,-1.6,0.3,0.2,0.2,0.2,0,0...   \n",
       "18178      X6R8R1  0,1.6,0.2,0.5,-1.8,1.6,4.9,1.9,3.6,6.9,0.7,2.3...   \n",
       "\n",
       "                                   phyloP30way_mammalian  \n",
       "0      0.3,0.3,-0.5,-1.5,-0.8,-0.3,-0.1,0,-0.1,-0.1,-...  \n",
       "1      0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0....  \n",
       "2      1.2,0.6,1.2,0.9,1.2,1.3,1.1,0.7,0.9,-0.1,1.1,0...  \n",
       "3      0.9,0.7,0.8,-0.2,0.5,1,0.6,0,0.4,0.1,0.1,0.9,0...  \n",
       "4      1,0.9,0.7,0.9,0.9,0.9,0.1,0.8,0.7,0.5,0.3,0.5,...  \n",
       "...                                                  ...  \n",
       "18174  1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2,1....  \n",
       "18175  0.3,0.8,1,0.7,1.1,1.1,-0.1,0.4,1.2,1.1,-0.1,0....  \n",
       "18176  1.2,0.6,-0.2,-0.7,-0.3,-0.7,0.2,-0.4,-0.7,-0.8...  \n",
       "18177  0.3,-0.4,0.3,-0.2,0.8,-0.1,1.1,0.1,0.3,0.1,0.2...  \n",
       "18178  0.5,1.1,-0.5,-0.9,-0.9,0.4,1,0.3,0.4,1,0.1,0.8...  \n",
       "\n",
       "[18179 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conservation\n",
    "phylop = pd.read_csv(\"../data/proteins_phylop_perresidue.tsv.gz\", sep=\"\\t\")\n",
    "phylop_features = ['phyloP100way_vertebrate', 'phyloP30way_mammalian']\n",
    "phylop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800dbcb-3bd4-4be6-8e42-075fd6c84d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read protein (graph) features\n",
    "archs_df = pd.read_csv(\"../data/archs_protein_embeds.tsv.gz\", sep=\"\\t\")\n",
    "go_df = pd.read_csv(\"../data/go_protein_embeds.tsv.gz\", sep=\"\\t\")\n",
    "string_df = pd.read_csv(\"../data/string_protein_embeds.tsv.gz\", sep=\"\\t\")\n",
    "gnomad_df = pd.read_csv(\"../data/gnomadv4_constraints.tsv.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648d4e3-c122-4508-b7c2-480e6d850675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# creat PyG objects\n",
    "all_pyg_graphs = []\n",
    "all_graphein_features = [\"amino_acid_one_hot\", \"expasy\", 'hbond_acceptors', 'hbond_donors', 'meiler', 'sidechain_vector', 'c_beta_vector', 'sequence_neighbour_vector_n_to_c']  # AAonehot 20, expasy = 61, hbond_acceptors=1, hbond_donors=1, meiler=7, sidechain_vector=3, c_beta_vector=3, sequence_neighbour_vector_n_to_c=3\n",
    "#all_g2p_features = [\"Accessible surface area (Å²)*\", \"Phi angle (degrees)*\", \"Psi angle (degrees)*\", \"ss_B\", \"ss_C\", \"ss_H\"]\n",
    "\n",
    "counter = 1\n",
    "for uniprot_id, hgnc, label in zip(all_uniprot_ids, all_hgnc, all_labels):\n",
    "\n",
    "    # remove those that are not in the describe_prot database\n",
    "    if uniprot_id not in describe_prot[\"UniprotEntry\"].values:\n",
    "        continue\n",
    "        \n",
    "    # construct a networkx graph from AlphaFold predictions\n",
    "    g = construct_graph(config=config, path=(af_db_path + prefix + uniprot_id + suffix))\n",
    "\n",
    "    add_sidechain_vector(g)\n",
    "    add_beta_carbon_vector(g)\n",
    "    add_sequence_neighbour_vector(g)\n",
    "    \n",
    "    # convert to PyG object\n",
    "    g2 = from_networkx(g)\n",
    "\n",
    "    '''\n",
    "    # ignore proteins with problematic length\n",
    "    if len(g2.residue_name) != describe_prot[describe_prot[\"UniprotEntry\"] == uniprot_id][\"seqlength\"].values[0]:\n",
    "        continue\n",
    "\n",
    "    if len(g2.residue_name) != uniprot_clean[uniprot_clean[\"Entry\"] == uniprot_id][\"Length\"].values[0]:\n",
    "        continue\n",
    "    '''\n",
    "    \n",
    "    # add graphein features\n",
    "    g2.x = g2[all_graphein_features[0]] \n",
    "    for feature in all_graphein_features[1:]:\n",
    "        g2.x = torch.cat((g2.x, g2[feature]), dim=1)\n",
    "\n",
    "    # add describe_prot features\n",
    "    for feature in describe_prot_featnames:\n",
    "        try:\n",
    "            temp_feature = describe_prot[describe_prot[\"UniprotEntry\"] == uniprot_id][feature].values[0]\n",
    "            temp_num_list = [float(num) for num in temp_feature.split(',')]\n",
    "            temp_num_tensor = torch.tensor(temp_num_list).reshape(-1, 1)\n",
    "            g2.x = torch.cat((g2.x, temp_num_tensor), dim=1)\n",
    "        except:\n",
    "            g2.x = torch.cat((g2.x, torch.full((len(g2.residue_name), 1), float('nan'))), dim=1)\n",
    "\n",
    "    # add uniprot features\n",
    "    for feature in uniprot_features:\n",
    "        try:\n",
    "            temp_feature = uniprot_clean[uniprot_clean[\"Entry\"] == uniprot_id][feature].values[0]\n",
    "            temp_num_list = [int(char) for char in temp_feature]\n",
    "            temp_num_tensor = torch.tensor(temp_num_list).reshape(-1, 1)\n",
    "            g2.x = torch.cat((g2.x, temp_num_tensor), dim=1)\n",
    "        except:\n",
    "            g2.x = torch.cat((g2.x, torch.full((len(g2.residue_name), 1), float('nan'))), dim=1)\n",
    "\n",
    "    # add phylop features\n",
    "    for feature in phylop_features:\n",
    "        try:\n",
    "            temp_feature = phylop[phylop[\"Entry\"] == uniprot_id][feature].values[0]\n",
    "            temp_num_list = [float(num) for num in temp_feature.split(',')]\n",
    "            temp_num_tensor = torch.tensor(temp_num_list).reshape(-1, 1)\n",
    "            g2.x = torch.cat((g2.x, temp_num_tensor), dim=1)\n",
    "        except:\n",
    "            g2.x = torch.cat((g2.x, torch.full((len(g2.residue_name), 1), float('nan'))), dim=1)\n",
    "    \n",
    "    # add protT5 embeddings\n",
    "    with h5py.File('../data/protT5_per_residue.h5', 'r') as f:\n",
    "        embeds = f[uniprot_id][:]  \n",
    "\n",
    "    '''\n",
    "    if embeds.shape[0] != g2.x.shape[0]:\n",
    "        continue\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        g2.x = torch.cat((g2.x, torch.from_numpy(embeds)), dim=1)\n",
    "    except:\n",
    "        g2.x = torch.cat((g2.x, torch.full((len(g2.residue_name), 1024), float('nan'))), dim=1)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # add G2P features\n",
    "    g2p_features = g2papi.get_protein_features(geneName=hgnc, uniprotId=uniprot_id)\n",
    "    g2p_features['ss_B'] = g2p_features['Secondary structure (DSSP 3-state)*'].apply(lambda x: 1 if x == 'B (strand)' else 0)\n",
    "    g2p_features['ss_C'] = g2p_features['Secondary structure (DSSP 3-state)*'].apply(lambda x: 1 if x == 'C (loop/coil)' else 0)\n",
    "    g2p_features['ss_H'] = g2p_features['Secondary structure (DSSP 3-state)*'].apply(lambda x: 1 if x == 'H (helix)' else 0)\n",
    "    g2p_features2 = g2p_features[all_g2p_features]\n",
    "    g2.x = torch.cat((g2.x, torch.tensor(g2p_features2.values, dtype=torch.float32)), dim=1) \n",
    "    '''\n",
    "\n",
    "    # add protein (graph) features\n",
    "    try:\n",
    "        archs_embed = torch.tensor(archs_df[archs_df[\"uniprot_ids\"] == uniprot_id].values[0][1:].tolist())\n",
    "    except:\n",
    "        archs_embed = torch.full((256,), float('nan'))\n",
    "\n",
    "    try:\n",
    "        go_embed = torch.tensor(go_df[go_df[\"uniprot_ids\"] == uniprot_id].values[0][1:].tolist())\n",
    "    except:\n",
    "        go_embed = torch.full((256,), float('nan'))\n",
    "\n",
    "    try:\n",
    "        string_embed = torch.tensor(string_df[string_df[\"uniprot_ids\"] == uniprot_id].values[0][1:].tolist())\n",
    "    except:\n",
    "        string_embed = torch.full((256,), float('nan'))\n",
    "\n",
    "    try:\n",
    "        gnomad_constraints = torch.tensor(gnomad_df[gnomad_df[\"uniprot_ids\"] == uniprot_id].values[0][1:].tolist())\n",
    "    except:\n",
    "        gnomad_constraints = torch.full((6,), float('nan'))\n",
    "\n",
    "    g2.u = torch.tensor([])\n",
    "    g2.u = torch.cat((g2.u, archs_embed, go_embed, string_embed, gnomad_constraints))\n",
    "\n",
    "    # add label\n",
    "    g2.y = label\n",
    "\n",
    "    all_pyg_graphs.append(g2)\n",
    "    print(f\"finished {counter} proteins\")\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70287c76-9fdf-41c8-af4c-59122f4971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple version of all pyg graphs\n",
    "\n",
    "all_pyg_graphs_simple = []\n",
    "\n",
    "for pyg in all_pyg_graphs:\n",
    "    \n",
    "    simple_pyg = Data(\n",
    "        x=pyg.x,               # Node features\n",
    "        y=pyg.y,               # Labels\n",
    "        batch=pyg.batch,       # Batch information\n",
    "        edge_index=pyg.edge_index,  # Edge connections\n",
    "        name = pyg.name,\n",
    "        u=pyg.u,\n",
    "        coords=pyg.coords\n",
    "    )\n",
    "\n",
    "    all_pyg_graphs_simple.append(simple_pyg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56eb0b-8775-4339-8c61-3106ee987764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all_pyg_graphs and all_pyg_graphs_simple\n",
    "'''\n",
    "with open('../res/pyg_graphs/all_pyg_graphs_simple.pkl', 'wb') as f:\n",
    "    pickle.dump(all_pyg_graphs_simple, f)\n",
    "\n",
    "with open('../res/pyg_graphs/all_pyg_graphs.pkl', 'wb') as f:\n",
    "    pickle.dump(all_pyg_graphs, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d445cc5d-b6e3-47c6-ac5f-752d24841ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all_pyg_graphs_simple\n",
    "\n",
    "with open('../res/pyg_graphs/all_pyg_graphs_simple.pkl', 'rb') as file:\n",
    "    all_pyg_graphs_simple = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d95a1764-8e95-4371-bd54-294513d01274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove protLM features\n",
    "\n",
    "for graph in all_pyg_graphs_simple:\n",
    "    # Ensure that the number of columns is greater than 1024\n",
    "    if graph.x.size(1) > 1024:\n",
    "        graph.x = graph.x[:, :-1024] \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f48cfa-20be-42a9-a5ad-fb9c9aa92468",
   "metadata": {},
   "source": [
    "### Replace graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f826eb0-fb52-4cdd-8e93-6f5696bcb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_uniprot_ids_features(df):\n",
    "    df_split = df.assign(uniprot_ids=df['uniprot_ids'].str.split('|'))\n",
    "\n",
    "    # Explode the lists into multiple rows\n",
    "    df_exploded = df_split.explode('uniprot_ids')\n",
    "\n",
    "    return df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c902577d-fabe-4879-9571-faecadc0222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>flDPnn_disorder</th>\n",
       "      <th>PSIPRED_helix</th>\n",
       "      <th>PSIPRED_strand</th>\n",
       "      <th>PSIPRED_coil</th>\n",
       "      <th>MMseq2_low_conservation</th>\n",
       "      <th>MMseq2_high_conservation</th>\n",
       "      <th>MMseq2_median</th>\n",
       "      <th>SignalP</th>\n",
       "      <th>DFLpred_linker</th>\n",
       "      <th>ASAquick_buried</th>\n",
       "      <th>DisoRDPbind_RNA</th>\n",
       "      <th>DisoRDPbind_DNA</th>\n",
       "      <th>DisoRDPbind_PRO</th>\n",
       "      <th>MoRFchibi_morf</th>\n",
       "      <th>DRNApred_RNA</th>\n",
       "      <th>DRNApred_DNA</th>\n",
       "      <th>SCRIBER_PRO</th>\n",
       "      <th>PTM_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A024R1R8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A024RBG1</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A075B6H5</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A075B6H7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A075B6H8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20531</th>\n",
       "      <td>V9GZ13</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20532</th>\n",
       "      <td>W5XKT8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20533</th>\n",
       "      <td>W6CW81</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20534</th>\n",
       "      <td>X5D2U9</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20535</th>\n",
       "      <td>X6R8D5</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20536 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot_ids  flDPnn_disorder  PSIPRED_helix  PSIPRED_strand  \\\n",
       "0      A0A024R1R8            1.000          0.594           0.000   \n",
       "1      A0A024RBG1            0.271          0.271           0.188   \n",
       "2      A0A075B6H5            0.131          0.238           0.308   \n",
       "3      A0A075B6H7            0.000          0.164           0.328   \n",
       "4      A0A075B6H8            0.000          0.265           0.222   \n",
       "...           ...              ...            ...             ...   \n",
       "20531      V9GZ13            0.540          0.800           0.000   \n",
       "20532      W5XKT8            0.000          0.556           0.133   \n",
       "20533      W6CW81            0.212          0.513           0.062   \n",
       "20534      X5D2U9            0.041          0.316           0.312   \n",
       "20535      X6R8D5            0.402          0.118           0.173   \n",
       "\n",
       "       PSIPRED_coil  MMseq2_low_conservation  MMseq2_high_conservation  \\\n",
       "0             0.406                     0.02                      0.08   \n",
       "1             0.541                     0.01                      0.13   \n",
       "2             0.454                     0.02                      0.12   \n",
       "3             0.508                     0.02                      0.15   \n",
       "4             0.513                     0.00                      0.17   \n",
       "...             ...                      ...                       ...   \n",
       "20531         0.200                     0.02                      0.22   \n",
       "20532         0.311                     0.06                      0.11   \n",
       "20533         0.425                     0.00                      0.09   \n",
       "20534         0.372                     0.00                      0.14   \n",
       "20535         0.709                     0.03                      0.11   \n",
       "\n",
       "       MMseq2_median  SignalP  DFLpred_linker  ASAquick_buried  \\\n",
       "0              2.705      0.0           0.000            0.000   \n",
       "1              2.810      0.0           0.116            0.265   \n",
       "2              2.610      1.0           0.062            0.131   \n",
       "3              2.580      1.0           0.259            0.207   \n",
       "4              2.750      1.0           0.068            0.282   \n",
       "...              ...      ...             ...              ...   \n",
       "20531          2.695      0.0           0.000            0.000   \n",
       "20532          2.370      0.0           0.006            0.312   \n",
       "20533          2.680      0.0           0.133            0.133   \n",
       "20534          2.785      1.0           0.011            0.233   \n",
       "20535          2.600      0.0           0.000            0.157   \n",
       "\n",
       "       DisoRDPbind_RNA  DisoRDPbind_DNA  DisoRDPbind_PRO  MoRFchibi_morf  \\\n",
       "0                 0.00            0.406            0.000           0.656   \n",
       "1                 0.00            0.000            0.000           0.000   \n",
       "2                 0.00            0.000            0.000           0.000   \n",
       "3                 0.00            0.000            0.000           0.000   \n",
       "4                 0.00            0.000            0.000           0.000   \n",
       "...                ...              ...              ...             ...   \n",
       "20531             0.12            0.000            0.000           1.000   \n",
       "20532             0.00            0.000            0.000           0.000   \n",
       "20533             0.00            0.000            0.000           0.000   \n",
       "20534             0.00            0.000            0.000           0.000   \n",
       "20535             0.00            0.000            0.016           0.047   \n",
       "\n",
       "       DRNApred_RNA  DRNApred_DNA  SCRIBER_PRO  PTM_content  \n",
       "0             0.266          0.00        0.078        0.109  \n",
       "1             0.000          0.00        0.000        0.072  \n",
       "2             0.000          0.00        0.000        0.054  \n",
       "3             0.000          0.05        0.000        0.147  \n",
       "4             0.000          0.20        0.000        0.068  \n",
       "...             ...           ...          ...          ...  \n",
       "20531         0.000          0.54        0.440        0.080  \n",
       "20532         0.000          0.01        0.000        0.034  \n",
       "20533         0.000          0.12        0.000        0.124  \n",
       "20534         0.000          0.00        0.000        0.045  \n",
       "20535         0.000          0.00        0.339        0.063  \n",
       "\n",
       "[20536 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read features\n",
    "describe_prot = clean_uniprot_ids_features(pd.read_csv(\"../data/describe_prot.tsv.gz\", sep=\"\\t\"))\n",
    "describe_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c8cac5-c7d1-4b51-b448-fdfc1de32d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>CDS_GC</th>\n",
       "      <th>UTR3_length</th>\n",
       "      <th>UTR3_GC</th>\n",
       "      <th>transcript_length</th>\n",
       "      <th>num_exons</th>\n",
       "      <th>transcript_GC</th>\n",
       "      <th>UTR5_length</th>\n",
       "      <th>UTR5_GC</th>\n",
       "      <th>CDS_length</th>\n",
       "      <th>...</th>\n",
       "      <th>Extracellular</th>\n",
       "      <th>GolgiApparatus</th>\n",
       "      <th>LysosomeOrVacuole</th>\n",
       "      <th>Mitochondrion</th>\n",
       "      <th>Nucleus</th>\n",
       "      <th>Peroxisome</th>\n",
       "      <th>Plastid</th>\n",
       "      <th>MembraneBound</th>\n",
       "      <th>Soluble</th>\n",
       "      <th>UNEECON_G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O43657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9H2S6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O60762</td>\n",
       "      <td>0.412516</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0.255725</td>\n",
       "      <td>23663.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.398301</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q8IZE3</td>\n",
       "      <td>0.450411</td>\n",
       "      <td>4082.0</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>44266.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.400330</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>2.229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.149153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9NSG2</td>\n",
       "      <td>0.420765</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>0.354986</td>\n",
       "      <td>59041.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.370725</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>2.562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.099038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17902</th>\n",
       "      <td>Q14184</td>\n",
       "      <td>0.620662</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>0.568573</td>\n",
       "      <td>38862.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.564459</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>1.239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17903</th>\n",
       "      <td>Q8WU43</td>\n",
       "      <td>0.384058</td>\n",
       "      <td>835.0</td>\n",
       "      <td>0.398802</td>\n",
       "      <td>9963.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.423065</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.507752</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>Q13224</td>\n",
       "      <td>0.540965</td>\n",
       "      <td>25446.0</td>\n",
       "      <td>0.418180</td>\n",
       "      <td>444266.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.405633</td>\n",
       "      <td>708.0</td>\n",
       "      <td>0.477401</td>\n",
       "      <td>4.455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>Q9Y675</td>\n",
       "      <td>0.532407</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.342318</td>\n",
       "      <td>13423.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.415108</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.191191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>Q8NAP8</td>\n",
       "      <td>0.553763</td>\n",
       "      <td>11268.0</td>\n",
       "      <td>0.416578</td>\n",
       "      <td>31615.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.451241</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17945 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot_ids    CDS_GC  UTR3_length   UTR3_GC  transcript_length  \\\n",
       "0          O43657       NaN          NaN       NaN                NaN   \n",
       "1          Q9H2S6       NaN          NaN       NaN                NaN   \n",
       "2          O60762  0.412516        262.0  0.255725            23663.0   \n",
       "3          Q8IZE3  0.450411       4082.0  0.376286            44266.0   \n",
       "4          Q9NSG2  0.420765       1093.0  0.354986            59041.0   \n",
       "...           ...       ...          ...       ...                ...   \n",
       "17902      Q14184  0.620662       4652.0  0.568573            38862.0   \n",
       "17903      Q8WU43  0.384058        835.0  0.398802             9963.0   \n",
       "17904      Q13224  0.540965      25446.0  0.418180           444266.0   \n",
       "17905      Q9Y675  0.532407        371.0  0.342318            13423.0   \n",
       "17906      Q8NAP8  0.553763      11268.0  0.416578            31615.0   \n",
       "\n",
       "       num_exons  transcript_GC  UTR5_length   UTR5_GC  CDS_length  ...  \\\n",
       "0            NaN            NaN          NaN       NaN         NaN  ...   \n",
       "1            NaN            NaN          NaN       NaN         NaN  ...   \n",
       "2            9.0       0.398301          9.0  0.666667       0.888  ...   \n",
       "3           13.0       0.400330        159.0  0.622642       2.229  ...   \n",
       "4           25.0       0.370725        356.0  0.426966       2.562  ...   \n",
       "...          ...            ...          ...       ...         ...  ...   \n",
       "17902        9.0       0.564459        171.0  0.877193       1.239  ...   \n",
       "17903        4.0       0.423065        516.0  0.507752       0.276  ...   \n",
       "17904       14.0       0.405633        708.0  0.477401       4.455  ...   \n",
       "17905        3.0       0.415108         63.0  0.682540       0.216  ...   \n",
       "17906        4.0       0.451241         75.0  0.640000       1.488  ...   \n",
       "\n",
       "       Extracellular  GolgiApparatus  LysosomeOrVacuole  Mitochondrion  \\\n",
       "0                0.0             0.0                0.0            0.0   \n",
       "1                0.0             0.0                0.0            0.0   \n",
       "2                0.0             0.0                0.0            0.0   \n",
       "3                0.0             0.0                0.0            0.0   \n",
       "4                0.0             0.0                0.0            0.0   \n",
       "...              ...             ...                ...            ...   \n",
       "17902            0.0             0.0                0.0            0.0   \n",
       "17903            0.0             0.0                0.0            0.0   \n",
       "17904            0.0             0.0                0.0            0.0   \n",
       "17905            0.0             0.0                0.0            0.0   \n",
       "17906            0.0             0.0                0.0            0.0   \n",
       "\n",
       "       Nucleus  Peroxisome  Plastid  MembraneBound  Soluble  UNEECON_G  \n",
       "0          0.0         0.0      0.0            1.0      0.0   0.098656  \n",
       "1          0.0         0.0      0.0            1.0      0.0   0.182126  \n",
       "2          0.0         0.0      0.0            1.0      0.0   0.255389  \n",
       "3          0.0         0.0      0.0            0.0      1.0   0.149153  \n",
       "4          1.0         0.0      0.0            0.0      1.0   0.099038  \n",
       "...        ...         ...      ...            ...      ...        ...  \n",
       "17902      0.0         0.0      0.0            0.0      1.0        NaN  \n",
       "17903      1.0         0.0      0.0            0.0      1.0   0.134916  \n",
       "17904      0.0         0.0      0.0            1.0      0.0   0.676874  \n",
       "17905      1.0         0.0      0.0            0.0      1.0   0.191191  \n",
       "17906      1.0         0.0      0.0            0.0      1.0   0.060722  \n",
       "\n",
       "[17945 rows x 53 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shet_features = clean_uniprot_ids_features(pd.read_csv(\"../data/shet_selected_features.tsv.gz\", sep=\"\\t\"))\n",
    "shet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7adb8227-7a7b-453c-86ed-95c62a4a89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>dn_ds</th>\n",
       "      <th>abundance</th>\n",
       "      <th>exp_var</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>median_scriber</th>\n",
       "      <th>n_paralogs</th>\n",
       "      <th>max_id</th>\n",
       "      <th>shet</th>\n",
       "      <th>nc_gerp</th>\n",
       "      <th>membrane_propensity</th>\n",
       "      <th>efx_raw</th>\n",
       "      <th>efx_abs</th>\n",
       "      <th>aco</th>\n",
       "      <th>pi</th>\n",
       "      <th>strand_pct</th>\n",
       "      <th>helix_pct</th>\n",
       "      <th>pct_buried</th>\n",
       "      <th>plddt</th>\n",
       "      <th>ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P04217</td>\n",
       "      <td>0.281393</td>\n",
       "      <td>1703.000</td>\n",
       "      <td>27771.571936</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.243542</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-1.041153</td>\n",
       "      <td>0.059434</td>\n",
       "      <td>-2.200350</td>\n",
       "      <td>-4.119574</td>\n",
       "      <td>22.958808</td>\n",
       "      <td>5.473445</td>\n",
       "      <td>0.462626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440404</td>\n",
       "      <td>86.520343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NQ94</td>\n",
       "      <td>0.262739</td>\n",
       "      <td>3.880</td>\n",
       "      <td>403.367145</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>2.137678</td>\n",
       "      <td>0.517310</td>\n",
       "      <td>-4.807986</td>\n",
       "      <td>-10.895981</td>\n",
       "      <td>12.649005</td>\n",
       "      <td>9.083333</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.208754</td>\n",
       "      <td>0.276094</td>\n",
       "      <td>69.012778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1764.000</td>\n",
       "      <td>76530.887282</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.717096</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.702367</td>\n",
       "      <td>0.401971</td>\n",
       "      <td>-2.007261</td>\n",
       "      <td>-4.003098</td>\n",
       "      <td>52.662712</td>\n",
       "      <td>6.253608</td>\n",
       "      <td>0.391452</td>\n",
       "      <td>0.140434</td>\n",
       "      <td>0.518318</td>\n",
       "      <td>82.030149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A8K2U0</td>\n",
       "      <td>0.336245</td>\n",
       "      <td>4.560</td>\n",
       "      <td>6760.359221</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.351444</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>-0.090234</td>\n",
       "      <td>0.056678</td>\n",
       "      <td>-1.956738</td>\n",
       "      <td>-3.768817</td>\n",
       "      <td>52.418667</td>\n",
       "      <td>5.491150</td>\n",
       "      <td>0.392022</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>0.521320</td>\n",
       "      <td>80.948177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U3KPV4</td>\n",
       "      <td>0.406874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>-0.382439</td>\n",
       "      <td>0.124294</td>\n",
       "      <td>-2.870083</td>\n",
       "      <td>-4.546424</td>\n",
       "      <td>27.784167</td>\n",
       "      <td>10.955319</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>90.760618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20360</th>\n",
       "      <td>Q6WRX3</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.497987</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>-0.437928</td>\n",
       "      <td>0.063729</td>\n",
       "      <td>-2.799698</td>\n",
       "      <td>-4.661322</td>\n",
       "      <td>13.115206</td>\n",
       "      <td>9.033270</td>\n",
       "      <td>0.044796</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>0.519104</td>\n",
       "      <td>90.445138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20361</th>\n",
       "      <td>Q9C0D3</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.816</td>\n",
       "      <td>152.357502</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.154437</td>\n",
       "      <td>0.774037</td>\n",
       "      <td>0.049745</td>\n",
       "      <td>-3.132392</td>\n",
       "      <td>-5.204659</td>\n",
       "      <td>12.288397</td>\n",
       "      <td>6.596195</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.534946</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>92.442863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20362</th>\n",
       "      <td>Q15942</td>\n",
       "      <td>0.083230</td>\n",
       "      <td>239.000</td>\n",
       "      <td>12614.114609</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>0.406220</td>\n",
       "      <td>-0.027150</td>\n",
       "      <td>-4.641151</td>\n",
       "      <td>-11.855881</td>\n",
       "      <td>17.309842</td>\n",
       "      <td>6.371462</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.103147</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>62.941014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20363</th>\n",
       "      <td>O43149</td>\n",
       "      <td>0.181384</td>\n",
       "      <td>3.640</td>\n",
       "      <td>19.334703</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>-1.638749</td>\n",
       "      <td>-4.060054</td>\n",
       "      <td>25.580570</td>\n",
       "      <td>5.582886</td>\n",
       "      <td>0.104357</td>\n",
       "      <td>0.441067</td>\n",
       "      <td>0.410672</td>\n",
       "      <td>75.916846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20364</th>\n",
       "      <td>Q8IYH5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.410</td>\n",
       "      <td>11.397586</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187608</td>\n",
       "      <td>3.225782</td>\n",
       "      <td>-2.016385</td>\n",
       "      <td>-3.772134</td>\n",
       "      <td>-11.540155</td>\n",
       "      <td>4.782125</td>\n",
       "      <td>5.553829</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.153931</td>\n",
       "      <td>0.075305</td>\n",
       "      <td>53.774574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20365 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot_ids     dn_ds  abundance       exp_var  betweenness  \\\n",
       "0          P04217  0.281393   1703.000  27771.571936     0.000053   \n",
       "1          Q9NQ94  0.262739      3.880    403.367145     0.000186   \n",
       "2          P01023       NaN   1764.000  76530.887282     0.000131   \n",
       "3          A8K2U0  0.336245      4.560   6760.359221     0.000035   \n",
       "4          U3KPV4  0.406874      0.000      0.008581     0.000018   \n",
       "...           ...       ...        ...           ...          ...   \n",
       "20360      Q6WRX3  0.598997      0.322      0.497987     0.000015   \n",
       "20361      Q9C0D3  0.066092      0.816    152.357502     0.000068   \n",
       "20362      Q15942  0.083230    239.000  12614.114609     0.000123   \n",
       "20363      O43149  0.181384      3.640     19.334703     0.000114   \n",
       "20364      Q8IYH5       NaN      1.410     11.397586     0.000148   \n",
       "\n",
       "       median_scriber  n_paralogs    max_id      shet   nc_gerp  \\\n",
       "0              0.0990        25.0  0.243542  0.000502 -1.041153   \n",
       "1              0.0830        36.0  0.487805  0.016500  2.137678   \n",
       "2              0.0630         8.0  0.717096  0.010068  0.702367   \n",
       "3              0.0590         8.0  0.351444  0.000361 -0.090234   \n",
       "4              0.1300         3.0  0.338235  0.001066 -0.382439   \n",
       "...               ...         ...       ...       ...       ...   \n",
       "20360          0.0925         2.0  0.000000  0.000405 -0.437928   \n",
       "20361          0.1180         2.0  0.596774  0.154437  0.774037   \n",
       "20362          0.1260         1.0  0.000000  0.008041  0.406220   \n",
       "20363          0.0180         0.0  0.000000  0.057000  0.009405   \n",
       "20364          0.0790         0.0  0.000000  0.187608  3.225782   \n",
       "\n",
       "       membrane_propensity   efx_raw    efx_abs        aco         pi  \\\n",
       "0                 0.059434 -2.200350  -4.119574  22.958808   5.473445   \n",
       "1                 0.517310 -4.807986 -10.895981  12.649005   9.083333   \n",
       "2                 0.401971 -2.007261  -4.003098  52.662712   6.253608   \n",
       "3                 0.056678 -1.956738  -3.768817  52.418667   5.491150   \n",
       "4                 0.124294 -2.870083  -4.546424  27.784167  10.955319   \n",
       "...                    ...       ...        ...        ...        ...   \n",
       "20360             0.063729 -2.799698  -4.661322  13.115206   9.033270   \n",
       "20361             0.049745 -3.132392  -5.204659  12.288397   6.596195   \n",
       "20362            -0.027150 -4.641151 -11.855881  17.309842   6.371462   \n",
       "20363             0.026494 -1.638749  -4.060054  25.580570   5.582886   \n",
       "20364            -2.016385 -3.772134 -11.540155   4.782125   5.553829   \n",
       "\n",
       "       strand_pct  helix_pct  pct_buried      plddt  ct  \n",
       "0        0.462626   0.000000    0.440404  86.520343   0  \n",
       "1        0.188552   0.208754    0.276094  69.012778   0  \n",
       "2        0.391452   0.140434    0.518318  82.030149   0  \n",
       "3        0.392022   0.145805    0.521320  80.948177   0  \n",
       "4        0.147059   0.352941    0.517647  90.760618   0  \n",
       "...           ...        ...         ...        ...  ..  \n",
       "20360    0.044796   0.525692    0.519104  90.445138   0  \n",
       "20361    0.048387   0.534946    0.537634  92.442863   1  \n",
       "20362    0.080420   0.103147    0.131119  62.941014   0  \n",
       "20363    0.104357   0.441067    0.410672  75.916846   0  \n",
       "20364    0.016611   0.153931    0.075305  53.774574   0  \n",
       "\n",
       "[20365 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_DnGofLofPaper = clean_uniprot_ids_features(pd.read_csv(\"../data/features_DnGofLofPaper.tsv.gz\", sep=\"\\t\"))\n",
    "features_DnGofLofPaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b50b2df-3cb2-46c0-91ad-d0ea5b0eea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>phylop_5utr</th>\n",
       "      <th>ExAC_don_to_syn</th>\n",
       "      <th>mRNA_halflife_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P04217</td>\n",
       "      <td>-0.065900</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NQ94</td>\n",
       "      <td>0.354861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01023</td>\n",
       "      <td>0.115622</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A8K2U0</td>\n",
       "      <td>0.133771</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U3KPV4</td>\n",
       "      <td>0.136512</td>\n",
       "      <td>0.038461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>Q6WRX3</td>\n",
       "      <td>0.024796</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>Q9C0D3</td>\n",
       "      <td>0.842005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>Q15942</td>\n",
       "      <td>0.436891</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>O43149</td>\n",
       "      <td>0.665234</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>Q8IYH5</td>\n",
       "      <td>1.348856</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17415 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot_ids  phylop_5utr  ExAC_don_to_syn  mRNA_halflife_10\n",
       "0          P04217    -0.065900         0.010870                 0\n",
       "1          Q9NQ94     0.354861         0.000000                 0\n",
       "2          P01023     0.115622         0.009524                 1\n",
       "3          A8K2U0     0.133771         0.069959                 0\n",
       "4          U3KPV4     0.136512         0.038461                 0\n",
       "...           ...          ...              ...               ...\n",
       "17373      Q6WRX3     0.024796         0.057143                 0\n",
       "17374      Q9C0D3     0.842005         0.000000                 0\n",
       "17375      Q15942     0.436891         0.009091                 0\n",
       "17376      O43149     0.665234         0.009960                 0\n",
       "17377      Q8IYH5     1.348856         0.010101                 0\n",
       "\n",
       "[17415 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domino_features = clean_uniprot_ids_features(pd.read_csv(\"../data/domino_features.tsv.gz\", sep=\"\\t\"))\n",
    "domino_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c83ab1-5e0a-45cf-8c11-54e59a2a22b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>lof.pLI</th>\n",
       "      <th>lof.pNull</th>\n",
       "      <th>lof.pRec</th>\n",
       "      <th>lof.oe_ci.upper</th>\n",
       "      <th>mis.z_score</th>\n",
       "      <th>syn.z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P04217</td>\n",
       "      <td>1.770600e-16</td>\n",
       "      <td>0.842950</td>\n",
       "      <td>0.15705</td>\n",
       "      <td>1.340</td>\n",
       "      <td>-0.86092</td>\n",
       "      <td>-0.635490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9NQ94</td>\n",
       "      <td>7.656000e-10</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.99804</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.23730</td>\n",
       "      <td>0.017838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01023</td>\n",
       "      <td>9.756800e-20</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.99999</td>\n",
       "      <td>0.765</td>\n",
       "      <td>2.75870</td>\n",
       "      <td>1.836200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A8K2U0</td>\n",
       "      <td>1.712700e-40</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.89890</td>\n",
       "      <td>0.953</td>\n",
       "      <td>1.65710</td>\n",
       "      <td>0.951210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U3KPV4</td>\n",
       "      <td>1.016900e-06</td>\n",
       "      <td>0.424980</td>\n",
       "      <td>0.57502</td>\n",
       "      <td>1.529</td>\n",
       "      <td>-4.07990</td>\n",
       "      <td>-3.997000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17886</th>\n",
       "      <td>A0A1B0GTJ6</td>\n",
       "      <td>1.332200e-03</td>\n",
       "      <td>0.332020</td>\n",
       "      <td>0.66665</td>\n",
       "      <td>1.843</td>\n",
       "      <td>-0.12558</td>\n",
       "      <td>-0.270880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17887</th>\n",
       "      <td>X6R8R1</td>\n",
       "      <td>8.079800e-01</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.17903</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2.33740</td>\n",
       "      <td>2.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17888</th>\n",
       "      <td>A0A1W2PQ72</td>\n",
       "      <td>7.549600e-07</td>\n",
       "      <td>0.107530</td>\n",
       "      <td>0.89247</td>\n",
       "      <td>1.089</td>\n",
       "      <td>1.58890</td>\n",
       "      <td>0.390280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17889</th>\n",
       "      <td>A0A494BZU4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03599</td>\n",
       "      <td>1.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17890</th>\n",
       "      <td>A0A494C103</td>\n",
       "      <td>4.373700e-01</td>\n",
       "      <td>0.087820</td>\n",
       "      <td>0.47481</td>\n",
       "      <td>1.655</td>\n",
       "      <td>0.45557</td>\n",
       "      <td>0.861890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17928 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot_ids       lof.pLI  lof.pNull  lof.pRec  lof.oe_ci.upper  \\\n",
       "0          P04217  1.770600e-16   0.842950   0.15705            1.340   \n",
       "1          Q9NQ94  7.656000e-10   0.001961   0.99804            0.825   \n",
       "2          P01023  9.756800e-20   0.000010   0.99999            0.765   \n",
       "3          A8K2U0  1.712700e-40   0.101100   0.89890            0.953   \n",
       "4          U3KPV4  1.016900e-06   0.424980   0.57502            1.529   \n",
       "...           ...           ...        ...       ...              ...   \n",
       "17886  A0A1B0GTJ6  1.332200e-03   0.332020   0.66665            1.843   \n",
       "17887      X6R8R1  8.079800e-01   0.012984   0.17903            0.679   \n",
       "17888  A0A1W2PQ72  7.549600e-07   0.107530   0.89247            1.089   \n",
       "17889  A0A494BZU4           NaN        NaN       NaN              NaN   \n",
       "17890  A0A494C103  4.373700e-01   0.087820   0.47481            1.655   \n",
       "\n",
       "       mis.z_score  syn.z_score  \n",
       "0         -0.86092    -0.635490  \n",
       "1          1.23730     0.017838  \n",
       "2          2.75870     1.836200  \n",
       "3          1.65710     0.951210  \n",
       "4         -4.07990    -3.997000  \n",
       "...            ...          ...  \n",
       "17886     -0.12558    -0.270880  \n",
       "17887      2.33740     2.093100  \n",
       "17888      1.58890     0.390280  \n",
       "17889     -0.03599     1.104800  \n",
       "17890      0.45557     0.861890  \n",
       "\n",
       "[17928 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnomadv4_constraints = clean_uniprot_ids_features(pd.read_csv(\"../data/gnomadv4_constraints.tsv.gz\", sep=\"\\t\"))\n",
    "gnomadv4_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf8419c6-82f0-4820-b7ab-1448ab18d489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flDPnn_disorder</th>\n",
       "      <th>PSIPRED_helix</th>\n",
       "      <th>PSIPRED_strand</th>\n",
       "      <th>PSIPRED_coil</th>\n",
       "      <th>MMseq2_low_conservation</th>\n",
       "      <th>MMseq2_high_conservation</th>\n",
       "      <th>MMseq2_median</th>\n",
       "      <th>SignalP</th>\n",
       "      <th>DFLpred_linker</th>\n",
       "      <th>ASAquick_buried</th>\n",
       "      <th>...</th>\n",
       "      <th>ct</th>\n",
       "      <th>phylop_5utr</th>\n",
       "      <th>ExAC_don_to_syn</th>\n",
       "      <th>mRNA_halflife_10</th>\n",
       "      <th>lof.pLI</th>\n",
       "      <th>lof.pNull</th>\n",
       "      <th>lof.pRec</th>\n",
       "      <th>lof.oe_ci.upper</th>\n",
       "      <th>mis.z_score</th>\n",
       "      <th>syn.z_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A024R1R8</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A024RBG1</th>\n",
       "      <td>0.271</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A024RCN7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6H5</th>\n",
       "      <td>0.131</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6H7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W5XKT8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W6CW81</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5D2U9</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.233</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6R8D5</th>\n",
       "      <td>0.402</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6R8R1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80798</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.17903</td>\n",
       "      <td>0.679</td>\n",
       "      <td>2.3374</td>\n",
       "      <td>2.0931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20958 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             flDPnn_disorder  PSIPRED_helix  PSIPRED_strand  PSIPRED_coil  \\\n",
       "uniprot_ids                                                                 \n",
       "A0A024R1R8             1.000          0.594           0.000         0.406   \n",
       "A0A024RBG1             0.271          0.271           0.188         0.541   \n",
       "A0A024RCN7               NaN            NaN             NaN           NaN   \n",
       "A0A075B6H5             0.131          0.238           0.308         0.454   \n",
       "A0A075B6H7             0.000          0.164           0.328         0.508   \n",
       "...                      ...            ...             ...           ...   \n",
       "W5XKT8                 0.000          0.556           0.133         0.311   \n",
       "W6CW81                 0.212          0.513           0.062         0.425   \n",
       "X5D2U9                 0.041          0.316           0.312         0.372   \n",
       "X6R8D5                 0.402          0.118           0.173         0.709   \n",
       "X6R8R1                   NaN            NaN             NaN           NaN   \n",
       "\n",
       "             MMseq2_low_conservation  MMseq2_high_conservation  MMseq2_median  \\\n",
       "uniprot_ids                                                                     \n",
       "A0A024R1R8                      0.02                      0.08          2.705   \n",
       "A0A024RBG1                      0.01                      0.13          2.810   \n",
       "A0A024RCN7                       NaN                       NaN            NaN   \n",
       "A0A075B6H5                      0.02                      0.12          2.610   \n",
       "A0A075B6H7                      0.02                      0.15          2.580   \n",
       "...                              ...                       ...            ...   \n",
       "W5XKT8                          0.06                      0.11          2.370   \n",
       "W6CW81                          0.00                      0.09          2.680   \n",
       "X5D2U9                          0.00                      0.14          2.785   \n",
       "X6R8D5                          0.03                      0.11          2.600   \n",
       "X6R8R1                           NaN                       NaN            NaN   \n",
       "\n",
       "             SignalP  DFLpred_linker  ASAquick_buried  ...   ct  phylop_5utr  \\\n",
       "uniprot_ids                                            ...                     \n",
       "A0A024R1R8       0.0           0.000            0.000  ...  0.0          NaN   \n",
       "A0A024RBG1       0.0           0.116            0.265  ...  0.0          NaN   \n",
       "A0A024RCN7       NaN             NaN              NaN  ...  0.0          NaN   \n",
       "A0A075B6H5       1.0           0.062            0.131  ...  0.0          NaN   \n",
       "A0A075B6H7       1.0           0.259            0.207  ...  0.0          NaN   \n",
       "...              ...             ...              ...  ...  ...          ...   \n",
       "W5XKT8           0.0           0.006            0.312  ...  0.0          NaN   \n",
       "W6CW81           0.0           0.133            0.133  ...  0.0          NaN   \n",
       "X5D2U9           1.0           0.011            0.233  ...  NaN          NaN   \n",
       "X6R8D5           0.0           0.000            0.157  ...  0.0          NaN   \n",
       "X6R8R1           NaN             NaN              NaN  ...  0.0          NaN   \n",
       "\n",
       "             ExAC_don_to_syn  mRNA_halflife_10  lof.pLI  lof.pNull  lof.pRec  \\\n",
       "uniprot_ids                                                                    \n",
       "A0A024R1R8               NaN               NaN      NaN        NaN       NaN   \n",
       "A0A024RBG1               NaN               NaN      NaN        NaN       NaN   \n",
       "A0A024RCN7               NaN               NaN      NaN        NaN       NaN   \n",
       "A0A075B6H5               NaN               NaN      NaN        NaN       NaN   \n",
       "A0A075B6H7               NaN               NaN      NaN        NaN       NaN   \n",
       "...                      ...               ...      ...        ...       ...   \n",
       "W5XKT8                   NaN               NaN      NaN        NaN       NaN   \n",
       "W6CW81                   NaN               NaN      NaN        NaN       NaN   \n",
       "X5D2U9                   NaN               NaN      NaN        NaN       NaN   \n",
       "X6R8D5                   NaN               NaN      NaN        NaN       NaN   \n",
       "X6R8R1                   NaN               NaN  0.80798   0.012984   0.17903   \n",
       "\n",
       "             lof.oe_ci.upper  mis.z_score  syn.z_score  \n",
       "uniprot_ids                                             \n",
       "A0A024R1R8               NaN          NaN          NaN  \n",
       "A0A024RBG1               NaN          NaN          NaN  \n",
       "A0A024RCN7               NaN          NaN          NaN  \n",
       "A0A075B6H5               NaN          NaN          NaN  \n",
       "A0A075B6H7               NaN          NaN          NaN  \n",
       "...                      ...          ...          ...  \n",
       "W5XKT8                   NaN          NaN          NaN  \n",
       "W6CW81                   NaN          NaN          NaN  \n",
       "X5D2U9                   NaN          NaN          NaN  \n",
       "X6R8D5                   NaN          NaN          NaN  \n",
       "X6R8R1                 0.679       2.3374       2.0931  \n",
       "\n",
       "[20958 rows x 97 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all feature dataframes on 'uniprot_ids'\n",
    "merged_features = describe_prot.set_index('uniprot_ids')\n",
    "merged_features = merged_features.join(shet_features.set_index('uniprot_ids'), how='outer')\n",
    "merged_features = merged_features.join(features_DnGofLofPaper.set_index('uniprot_ids'), how='outer')\n",
    "merged_features = merged_features.join(domino_features.set_index('uniprot_ids'), how='outer')\n",
    "merged_features = merged_features.join(gnomadv4_constraints.set_index('uniprot_ids'), how='outer')\n",
    "merged_features = merged_features.drop('betweenness', axis=1) #this comes from PPI so no need\n",
    "merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b79a01-8efc-4f7e-872b-b83d53983d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSIPRED_helix</th>\n",
       "      <th>PSIPRED_strand</th>\n",
       "      <th>ASAquick_buried</th>\n",
       "      <th>flDPnn_disorder</th>\n",
       "      <th>MoRFchibi_morf</th>\n",
       "      <th>DFLpred_linker</th>\n",
       "      <th>DisoRDPbind_RNA</th>\n",
       "      <th>DisoRDPbind_DNA</th>\n",
       "      <th>DisoRDPbind_PRO</th>\n",
       "      <th>DRNApred_RNA</th>\n",
       "      <th>...</th>\n",
       "      <th>mRNA_halflife_10</th>\n",
       "      <th>CDS_GC</th>\n",
       "      <th>UTR3_length</th>\n",
       "      <th>UTR3_GC</th>\n",
       "      <th>UTR5_length</th>\n",
       "      <th>UTR5_GC</th>\n",
       "      <th>transcript_length</th>\n",
       "      <th>Transcript_count</th>\n",
       "      <th>num_exons</th>\n",
       "      <th>connectedness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A024R1R8</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.266</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A024RBG1</th>\n",
       "      <td>0.271</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A024RCN7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6H5</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A075B6H7</th>\n",
       "      <td>0.164</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W5XKT8</th>\n",
       "      <td>0.556</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W6CW81</th>\n",
       "      <td>0.513</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5D2U9</th>\n",
       "      <td>0.316</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6R8D5</th>\n",
       "      <td>0.118</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6R8R1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20958 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PSIPRED_helix  PSIPRED_strand  ASAquick_buried  flDPnn_disorder  \\\n",
       "uniprot_ids                                                                    \n",
       "A0A024R1R8           0.594           0.000            0.000            1.000   \n",
       "A0A024RBG1           0.271           0.188            0.265            0.271   \n",
       "A0A024RCN7             NaN             NaN              NaN              NaN   \n",
       "A0A075B6H5           0.238           0.308            0.131            0.131   \n",
       "A0A075B6H7           0.164           0.328            0.207            0.000   \n",
       "...                    ...             ...              ...              ...   \n",
       "W5XKT8               0.556           0.133            0.312            0.000   \n",
       "W6CW81               0.513           0.062            0.133            0.212   \n",
       "X5D2U9               0.316           0.312            0.233            0.041   \n",
       "X6R8D5               0.118           0.173            0.157            0.402   \n",
       "X6R8R1                 NaN             NaN              NaN              NaN   \n",
       "\n",
       "             MoRFchibi_morf  DFLpred_linker  DisoRDPbind_RNA  DisoRDPbind_DNA  \\\n",
       "uniprot_ids                                                                     \n",
       "A0A024R1R8            0.656           0.000              0.0            0.406   \n",
       "A0A024RBG1            0.000           0.116              0.0            0.000   \n",
       "A0A024RCN7              NaN             NaN              NaN              NaN   \n",
       "A0A075B6H5            0.000           0.062              0.0            0.000   \n",
       "A0A075B6H7            0.000           0.259              0.0            0.000   \n",
       "...                     ...             ...              ...              ...   \n",
       "W5XKT8                0.000           0.006              0.0            0.000   \n",
       "W6CW81                0.000           0.133              0.0            0.000   \n",
       "X5D2U9                0.000           0.011              0.0            0.000   \n",
       "X6R8D5                0.047           0.000              0.0            0.000   \n",
       "X6R8R1                  NaN             NaN              NaN              NaN   \n",
       "\n",
       "             DisoRDPbind_PRO  DRNApred_RNA  ...  mRNA_halflife_10  CDS_GC  \\\n",
       "uniprot_ids                                 ...                             \n",
       "A0A024R1R8             0.000         0.266  ...               NaN     NaN   \n",
       "A0A024RBG1             0.000         0.000  ...               NaN     NaN   \n",
       "A0A024RCN7               NaN           NaN  ...               NaN     NaN   \n",
       "A0A075B6H5             0.000         0.000  ...               NaN     NaN   \n",
       "A0A075B6H7             0.000         0.000  ...               NaN     NaN   \n",
       "...                      ...           ...  ...               ...     ...   \n",
       "W5XKT8                 0.000         0.000  ...               NaN     NaN   \n",
       "W6CW81                 0.000         0.000  ...               NaN     NaN   \n",
       "X5D2U9                 0.000         0.000  ...               NaN     NaN   \n",
       "X6R8D5                 0.016         0.000  ...               NaN     NaN   \n",
       "X6R8R1                   NaN           NaN  ...               NaN     NaN   \n",
       "\n",
       "             UTR3_length  UTR3_GC  UTR5_length  UTR5_GC  transcript_length  \\\n",
       "uniprot_ids                                                                  \n",
       "A0A024R1R8           NaN      NaN          NaN      NaN                NaN   \n",
       "A0A024RBG1           NaN      NaN          NaN      NaN                NaN   \n",
       "A0A024RCN7           NaN      NaN          NaN      NaN                NaN   \n",
       "A0A075B6H5           NaN      NaN          NaN      NaN                NaN   \n",
       "A0A075B6H7           NaN      NaN          NaN      NaN                NaN   \n",
       "...                  ...      ...          ...      ...                ...   \n",
       "W5XKT8               NaN      NaN          NaN      NaN                NaN   \n",
       "W6CW81               NaN      NaN          NaN      NaN                NaN   \n",
       "X5D2U9               NaN      NaN          NaN      NaN                NaN   \n",
       "X6R8D5               NaN      NaN          NaN      NaN                NaN   \n",
       "X6R8R1               NaN      NaN          NaN      NaN                NaN   \n",
       "\n",
       "             Transcript_count  num_exons  connectedness  \n",
       "uniprot_ids                                              \n",
       "A0A024R1R8                NaN        NaN            NaN  \n",
       "A0A024RBG1                NaN        NaN            NaN  \n",
       "A0A024RCN7                NaN        NaN            NaN  \n",
       "A0A075B6H5                NaN        NaN            NaN  \n",
       "A0A075B6H7                NaN        NaN            NaN  \n",
       "...                       ...        ...            ...  \n",
       "W5XKT8                    NaN        NaN            NaN  \n",
       "W6CW81                    NaN        NaN            NaN  \n",
       "X5D2U9                    NaN        NaN            NaN  \n",
       "X6R8D5                    NaN        NaN            NaN  \n",
       "X6R8R1                    NaN        NaN            NaN  \n",
       "\n",
       "[20958 rows x 78 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_structure_and_function = {\n",
    "    'PSIPRED_helix': 'Prediction of helical secondary structures.',\n",
    "    'PSIPRED_strand': 'Prediction of beta-strand secondary structures.',\n",
    "    'ASAquick_buried': 'Prediction of buried surface area (solvent accessibility).',\n",
    "    'flDPnn_disorder': 'Prediction of intrinsically disordered regions.',\n",
    "    'MoRFchibi_morf': 'Prediction of molecular recognition features (MoRFs).',\n",
    "    'DFLpred_linker': 'Prediction of disordered flexible linker residues.',\n",
    "    'DisoRDPbind_RNA': 'Prediction of RNA-binding disordered regions.',\n",
    "    'DisoRDPbind_DNA': 'Prediction of DNA-binding disordered regions.',\n",
    "    'DisoRDPbind_PRO': 'Prediction of protein-binding disordered regions.',\n",
    "    'DRNApred_RNA': 'Prediction of RNA-binding residues.',\n",
    "    'DRNApred_DNA': 'Prediction of DNA-binding residues.',\n",
    "    'SignalP': 'Prediction of signal peptides.',\n",
    "    'SCRIBER_PRO': 'Prediction of protein-binding residues.',\n",
    "    'PTM_content': 'Prediction of post-translational modification sites.',\n",
    "    'membrane_propensity': 'Propensity for membrane association.',\n",
    "    'Plastid': 'Localization to plastid.',\n",
    "    'CellMembrane': 'Localization to cell membrane.',\n",
    "    'Cytoplasm': 'Localization to cytoplasm.',\n",
    "    'EndoplasmicReticulum': 'Localization to endoplasmic reticulum.',\n",
    "    'Extracellular': 'Localization to extracellular space.',\n",
    "    'GolgiApparatus': 'Localization to Golgi apparatus.',\n",
    "    'LysosomeOrVacuole': 'Localization to lysosome or vacuole.',\n",
    "    'Mitochondrion': 'Localization to mitochondrion.',\n",
    "    'Nucleus': 'Localization to nucleus.',\n",
    "    'Peroxisome': 'Localization to peroxisome.',\n",
    "    'MembraneBound': 'Membrane-bound proteins.',\n",
    "    'aco': 'Absolute contact order of the protein structure.',\n",
    "    'pct_buried': 'Fraction of buried residues in protein structure.',\n",
    "    'plddt': 'Mean pLDDT confidence score of predicted structures.',\n",
    "    'pi': 'Protein isoelectric point.',\n",
    "    'ct': 'Cotranslational assembly annotations.',\n",
    "    'efx_abs': 'Median ratio of ESM-1v and absolute FoldX ΔΔG for missense mutations.',\n",
    "    'efx_raw': 'Median ratio of ESM-1v and raw FoldX ΔΔG for missense mutations.',\n",
    "    'median_scriber': 'Median SCRIBER score for residues with more than 5% relative solvent accessible surface area.'\n",
    "}\n",
    "\n",
    "evolutionary_conservation_and_variation = {\n",
    "    'MMseq2_low_conservation': 'Low conservation from MMseqs.',\n",
    "    'MMseq2_high_conservation': 'High conservation from MMseqs.',\n",
    "    'phastCons7way_mean': 'Mean conservation score across 7 species.',\n",
    "    'phastCons7way_max': '95th percentile conservation score across 7 species.',\n",
    "    'phastCons17way_max': '95th percentile conservation score across 17 species.',\n",
    "    'phastCons100way_max': '95th percentile conservation score across 100 species.',\n",
    "    'fracCdsPhylopAm': 'Fraction of coding sequences constrained in 240 mammals.',\n",
    "    'dn_ds': 'Human-macaque dN/dS ratio of nonsynonymous to synonymous substitutions.',\n",
    "    'UNEECON_G': 'Evolutionary pressure score (UNEECON).',\n",
    "    'n_paralogs': 'Number of paralogous proteins.',\n",
    "    'max_id': 'Maximum sequence identity to paralogs.',\n",
    "    'nc_gerp': 'GERP++ score for non-coding regions.',\n",
    "    'phylop_5utr': 'Evolutionary conservation of 5\\' UTR.',\n",
    "    'ExAC_don_to_syn': 'Donor to synonymous mutation ratio from ExAC.',\n",
    "    'lof.pLI': 'Probability of being loss-of-function intolerant.',\n",
    "    'lof.pNull': 'Null hypothesis for loss-of-function.',\n",
    "    'lof.pRec': 'Probability of intolerance to homozygous but not heterozygous loss-of-function variants.',\n",
    "    'lof.oe_ci.upper': 'Upper confidence interval for loss-of-function over-expected score.',\n",
    "    'shet': 'Selection coefficient related to heterozygosity.',\n",
    "    'mis.z_score': 'Z-score for missense variation constraint.',\n",
    "    'syn.z_score': 'Z-score for synonymous variation constraint.'\n",
    "}\n",
    "\n",
    "\n",
    "transcripts_expression_regulation = {\n",
    "    'abundance': 'Protein abundance (from PaxDB).',\n",
    "    'exp_var': 'RNA expression variance across tissues.',\n",
    "    'tau': 'Tissue specificity of gene expression (0, broadly expressed to 1, tissue specific).',\n",
    "    'TF': 'Indicates if the gene is a transcription factor.',\n",
    "    'EDS': 'Enhancer domain score.',\n",
    "    'ABC_count1': 'Number of biosamples with an active ABC enhancer.',\n",
    "    'ABC_count2': 'Total number of ABC enhancers across all biosamples.',\n",
    "    'ABC_count3': 'Total number of ABC enhancers after union of enhancer domains.',\n",
    "    'ABC_length_per_type': 'Average ABC enhancer length per active cell type.',\n",
    "    'Roadmap_count1': 'Number of biosamples with an active Roadmap enhancer.',\n",
    "    'Roadmap_count2': 'Total number of Roadmap enhancers across all biosamples.',\n",
    "    'Roadmap_count3': 'Total number of Roadmap enhancers after union of enhancer domains.',\n",
    "    'promoter_count': 'Number of promoters.',\n",
    "    'mRNA_halflife_10': 'mRNA half-life in hours.',\n",
    "    'CDS_GC': 'GC content of the coding sequence.',\n",
    "    'UTR3_length': 'Length of 3\\' UTR.',\n",
    "    'UTR3_GC': 'GC content of 3\\' UTR.',\n",
    "    'UTR5_length': 'Length of 5\\' UTR.',\n",
    "    'UTR5_GC': 'GC content of 5\\' UTR.',\n",
    "    'transcript_length': 'Total transcript length.',\n",
    "    'Transcript_count': 'Number of transcripts.',\n",
    "    'num_exons': 'Number of exons.',\n",
    "    'connectedness': 'Overall connectedness in coexpression networks.'\n",
    "}\n",
    "\n",
    "selected_columns = list(protein_structure_and_function.keys()) +list(evolutionary_conservation_and_variation.keys()) + list(transcripts_expression_regulation.keys()) \n",
    "merged_features = merged_features[selected_columns]\n",
    "merged_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61189117-ba19-45a1-9cfd-56baf70ebad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch_geometric\n",
    "\n",
    "# Assuming `graphs` is your list of torch geometric graphs\n",
    "# And `df` is your dataframe with protein features\n",
    "\n",
    "# Function to extract the uniprot_id from the graph's name\n",
    "def extract_uniprot_id(graph_name):\n",
    "    # Use regex to extract the uniprot_id, which is between the first dash and the second dash\n",
    "    match = re.search(r'AF-(\\w+)-F1', graph_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Iterate through all graphs\n",
    "for graph in all_pyg_graphs_simple:\n",
    "    # Extract the uniprot_id from the graph's name\n",
    "    uniprot_id = extract_uniprot_id(graph.name)\n",
    "    \n",
    "    if uniprot_id in merged_features.index:\n",
    "        # Get the corresponding row of protein features from the DataFrame\n",
    "        protein_features = merged_features.loc[uniprot_id].values\n",
    "        \n",
    "        # Convert the features to a tensor (if needed, depending on your pipeline)\n",
    "        protein_features_tensor = torch.tensor(protein_features, dtype=torch.float)\n",
    "        \n",
    "        # Assign the features to graph.u\n",
    "        graph.u = protein_features_tensor\n",
    "    else:\n",
    "        print(f\"Protein {uniprot_id} not found in the DataFrame\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec228d9-1410-4b64-aa3b-99204ac532f1",
   "metadata": {},
   "source": [
    "### Train test split + Normalization + Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "724d5ad6-6472-4841-8997-ac6e65b10224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze graph freatures from 1*1*L to L\n",
    "for graph in all_pyg_graphs_simple:\n",
    "    graph.u = torch.squeeze(graph.u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "92296dcc-8137-4fa5-8c21-c640a3d92145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def stratified_split(graphs, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "    # Extract the labels (y) as tuples for stratification\n",
    "    labels = [tuple(graph.y) for graph in graphs]\n",
    "\n",
    "    # Split the data into training and temp (to split further into val and test)\n",
    "    train_graphs, temp_graphs, train_labels, temp_labels = train_test_split(\n",
    "        graphs, labels, test_size=(1 - train_size), stratify=labels, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Determine the proportion of the temp set to split into validation and test\n",
    "    val_test_ratio = val_size / (val_size + test_size)\n",
    "\n",
    "    # Split the remaining data (temp) into validation and test sets\n",
    "    val_graphs, test_graphs, val_labels, test_labels = train_test_split(\n",
    "        temp_graphs, temp_labels, test_size=(1 - val_test_ratio), stratify=temp_labels, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return train_graphs, val_graphs, test_graphs\n",
    "\n",
    "# Example usage:\n",
    "train_list, val_list, test_list = stratified_split(all_pyg_graphs_simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bd42e1e0-b47f-4d10-b139-ac57c1732c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      " {(0, 0, 1): 200, (0, 1, 0): 297, (1, 0, 1): 92, (1, 0, 0): 198, (1, 1, 1): 63, (1, 1, 0): 90, (0, 1, 1): 71}\n",
      "\n",
      "test:\n",
      " {(1, 1, 1): 7, (0, 1, 0): 37, (0, 0, 1): 25, (1, 0, 0): 25, (1, 1, 0): 12, (1, 0, 1): 12, (0, 1, 1): 9}\n",
      "\n",
      "val:\n",
      " {(1, 1, 0): 11, (1, 1, 1): 8, (1, 0, 0): 25, (0, 0, 1): 25, (0, 1, 0): 37, (1, 0, 1): 11, (0, 1, 1): 9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_label_occurrences(graphs):\n",
    "    # Create a dictionary to store the count of each unique label tuple\n",
    "    label_count = defaultdict(int)\n",
    "    \n",
    "    # Iterate over the list of graphs\n",
    "    for graph in graphs:\n",
    "        # Convert the label list to a tuple (as tuples are hashable and can be used as dict keys)\n",
    "        label_tuple = tuple(graph.y)\n",
    "        # Increment the count of this label\n",
    "        label_count[label_tuple] += 1\n",
    "    \n",
    "    return dict(label_count)\n",
    "\n",
    "print(f\"train:\\n {count_label_occurrences(train_list)}\\n\")\n",
    "print(f\"test:\\n {count_label_occurrences(test_list)}\\n\")\n",
    "print(f\"val:\\n {count_label_occurrences(val_list)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "08e71839-0b5c-47f4-8c04-4aca35642f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_normalize(graph_list):\n",
    "    for graph in graph_list:\n",
    "        # Get node features (x)\n",
    "        x = graph.x\n",
    "\n",
    "        # Step 1: Imputation (replace NaNs in non-one-hot columns using median)\n",
    "        col_median = torch.nanmedian(x, dim=0).values  # Calculate column median, ignoring NaNs\n",
    "\n",
    "        # Identify one-hot encoded columns (assuming values are exactly 0 or 1)\n",
    "        onehot_mask = torch.all((x == 0) | (x == 1), dim=0)\n",
    "\n",
    "        # Impute only non-one-hot columns\n",
    "        non_onehot_mask = ~onehot_mask\n",
    "        x[:, non_onehot_mask] = torch.where(torch.isnan(x[:, non_onehot_mask]), col_median[non_onehot_mask], x[:, non_onehot_mask])\n",
    "\n",
    "        # Step 2: Normalization (only normalize non-one-hot columns)\n",
    "        #max_values = torch.max(x[:, non_onehot_mask], dim=0).values  # Find max of each non-one-hot column\n",
    "        #max_values[max_values == 0] = 1  # Avoid division by zero\n",
    "        #x[:, non_onehot_mask] = x[:, non_onehot_mask] / max_values  # Normalize non-one-hot columns\n",
    "\n",
    "        # Assign the updated node features back to the graph\n",
    "        graph.x = x\n",
    "    \n",
    "    return graph_list\n",
    "\n",
    "\n",
    "train_list= impute_and_normalize(train_list)\n",
    "val_list = impute_and_normalize(val_list)\n",
    "test_list = impute_and_normalize(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e414247-a497-4d42-a55a-28853f224ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# normalize\\ntrain_list_norm = min_max_normalize_features_global(train_list_impute, global_min_node, global_max_node, global_min_graph, global_max_graph)\\ntest_list_norm = min_max_normalize_features_global(test_list_impute, global_min_node, global_max_node, global_min_graph, global_max_graph)\\nval_list_norm = min_max_normalize_features_global(val_list_impute, global_min_node, global_max_node, global_min_graph, global_max_graph)\\n'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_global_min_max_median(graphs):\n",
    "    ### Node features\n",
    "    # Concatenate features of all graphs along the node dimension\n",
    "    all_features = torch.cat([data.x for data in graphs], dim=0)\n",
    "    \n",
    "    # Mask NaN values by creating a boolean mask\n",
    "    nan_mask = torch.isnan(all_features)\n",
    "    \n",
    "    # Replace NaN values with a very large number for min and very small for max\n",
    "    all_features_min = all_features.clone()\n",
    "    all_features_max = all_features.clone()\n",
    "    \n",
    "    all_features_min[nan_mask] = float('inf')  # Use infinity for min\n",
    "    all_features_max[nan_mask] = -float('inf')  # Use negative infinity for max\n",
    "    \n",
    "    # Compute global min, max and median ignoring NaNs\n",
    "    global_min_node = torch.min(all_features_min, dim=0, keepdim=True)[0]\n",
    "    global_max_node = torch.max(all_features_max, dim=0, keepdim=True)[0]\n",
    "    \n",
    "    # For median, use nan-to-num to replace NaNs with a large number temporarily, then calculate the median\n",
    "    all_features_median = torch.nan_to_num(all_features, nan=0)\n",
    "    global_median_node = torch.median(all_features_median, dim=0, keepdim=True)[0]\n",
    "\n",
    "    ### graph features\n",
    "    # Concatenate features of all graphs along the node dimension\n",
    "    all_features = torch.stack([torch.squeeze(data.u) for data in graphs])\n",
    "    \n",
    "    # Mask NaN values by creating a boolean mask\n",
    "    nan_mask = torch.isnan(all_features)\n",
    "    \n",
    "    # Replace NaN values with a very large number for min and very small for max\n",
    "    all_features_min = all_features.clone()\n",
    "    all_features_max = all_features.clone()\n",
    "    \n",
    "    all_features_min[nan_mask] = float('inf')  # Use infinity for min\n",
    "    all_features_max[nan_mask] = -float('inf')  # Use negative infinity for max\n",
    "    \n",
    "    # Compute global min, max and median ignoring NaNs\n",
    "    global_min_graph = torch.min(all_features_min, dim=0, keepdim=True)[0]\n",
    "    global_max_graph = torch.max(all_features_max, dim=0, keepdim=True)[0]\n",
    "    \n",
    "    # For median, use nan-to-num to replace NaNs with a large number temporarily, then calculate the median\n",
    "    all_features_median = torch.nan_to_num(all_features, nan=0)\n",
    "    global_median_graph = torch.median(all_features_median, dim=0, keepdim=True)[0]\n",
    "    return global_min_node, global_max_node, global_median_node, global_min_graph, global_max_graph, global_median_graph \n",
    "\n",
    "\n",
    "def replace_nan_with_median(graphs, global_median_node, global_mdeian_graph):\n",
    "    # Replace NaN values with the median for each graph\n",
    "    for data in graphs:\n",
    "        # Replace NaN values in node feature matrix with the global median\n",
    "        data.x = torch.where(torch.isnan(data.x), global_median_node, data.x)\n",
    "\n",
    "        data.u = torch.where(torch.isnan(data.u), global_median_graph, data.u)\n",
    "        \n",
    "    return graphs\n",
    "\n",
    "\n",
    "def min_max_normalize_features_global(graphs, global_min_node, global_max_node, global_min_graph, global_max_graph):\n",
    "\n",
    "    #global_range_node = global_max_node - global_min_node + 1e-9  # To avoid division by zero\n",
    "    global_range_graph = global_max_graph - global_min_graph + 1e-9  # To avoid division by zero\n",
    "    \n",
    "    # Normalize each graph's features using the global min and max\n",
    "    for data in graphs:\n",
    "        #data.x = (data.x - global_min_node) / global_range_node\n",
    "        data.u = (data.u - global_min_graph) / global_range_graph\n",
    "        \n",
    "    return graphs\n",
    "\n",
    "# Compute global min and max based on train list\n",
    "global_min_node, global_max_node, global_median_node, global_min_graph, global_max_graph, global_median_graph = compute_global_min_max_median(train_list)\n",
    "\n",
    "# replace NaN\n",
    "train_list_norm = replace_nan_with_median(train_list, global_median_node, global_median_graph)\n",
    "test_list_norm = replace_nan_with_median(test_list, global_median_node, global_median_graph)\n",
    "val_list_norm = replace_nan_with_median(val_list, global_median_node, global_median_graph)\n",
    "\n",
    "'''\n",
    "# normalize\n",
    "train_list_norm = min_max_normalize_features_global(train_list_impute, global_min_node, global_max_node, global_min_graph, global_max_graph)\n",
    "test_list_norm = min_max_normalize_features_global(test_list_impute, global_min_node, global_max_node, global_min_graph, global_max_graph)\n",
    "val_list_norm = min_max_normalize_features_global(val_list_impute, global_min_node, global_max_node, global_min_graph, global_max_graph)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a12ede-f032-4d3a-a6d9-f5cf8c68a344",
   "metadata": {},
   "source": [
    "### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dbab53df-9e0f-4237-9dc3-42bf49462bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/15/24 10:42:51] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Deprotonating protein. This removes H atoms from the pdb_df dataframe    <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">graphs.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py#188\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/15/24 10:42:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Deprotonating protein. This removes H atoms from the pdb_df dataframe    \u001b]8;id=869921;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py\u001b\\\u001b[2mgraphs.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=91926;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py#188\u001b\\\u001b[2m188\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Detected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">968</span> total nodes                                                 <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">graphs.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py#435\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">435</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Detected \u001b[1;36m968\u001b[0m total nodes                                                 \u001b]8;id=332383;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py\u001b\\\u001b[2mgraphs.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=320470;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/graphs.py#435\u001b\\\u001b[2m435\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span> aromatic-aromatic interactions                               <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">distance.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#467\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">467</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found: \u001b[1;36m84\u001b[0m aromatic-aromatic interactions                               \u001b]8;id=269933;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\u001b\\\u001b[2mdistance.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=898112;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#467\u001b\\\u001b[2m467\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">404</span> hbond interactions.                                         <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">distance.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1344</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m404\u001b[0m hbond interactions.                                         \u001b]8;id=211704;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\u001b\\\u001b[2mdistance.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=106213;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\u001b\\\u001b[2m1344\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> hbond interactions.                                          <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">distance.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1344</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m41\u001b[0m hbond interactions.                                          \u001b]8;id=930457;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\u001b\\\u001b[2mdistance.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=481894;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\u001b\\\u001b[2m1344\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> disulfide interactions.                                      <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">distance.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1344</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m13\u001b[0m disulfide interactions.                                      \u001b]8;id=378802;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\u001b\\\u001b[2mdistance.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=976250;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\u001b\\\u001b[2m1344\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7862</span> ionic interactions.                                        <a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">distance.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1344</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m7862\u001b[0m ionic interactions.                                        \u001b]8;id=736536;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py\u001b\\\u001b[2mdistance.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=441632;file:///work/gr-fe/saadat/tools/python3_ven_jed/lib/python3.10/site-packages/graphein/protein/edges/distance.py#1344\u001b\\\u001b[2m1344\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['aa0',\n",
       " 'aa1',\n",
       " 'aa2',\n",
       " 'aa3',\n",
       " 'aa4',\n",
       " 'aa5',\n",
       " 'aa6',\n",
       " 'aa7',\n",
       " 'aa8',\n",
       " 'aa9',\n",
       " 'aa10',\n",
       " 'aa11',\n",
       " 'aa12',\n",
       " 'aa13',\n",
       " 'aa14',\n",
       " 'aa15',\n",
       " 'aa16',\n",
       " 'aa17',\n",
       " 'aa18',\n",
       " 'aa19',\n",
       " 'pka_cooh_alpha',\n",
       " 'pka_nh3',\n",
       " 'pka_rgroup',\n",
       " 'isoelectric_points',\n",
       " 'molecularweight',\n",
       " 'numbercodons',\n",
       " 'bulkiness',\n",
       " 'polarityzimmerman',\n",
       " 'polaritygrantham',\n",
       " 'refractivity',\n",
       " 'recognitionfactors',\n",
       " 'hphob_eisenberg',\n",
       " 'hphob_sweet',\n",
       " 'hphob_woods',\n",
       " 'hphob_doolittle',\n",
       " 'hphob_manavalan',\n",
       " 'hphob_leo',\n",
       " 'hphob_black',\n",
       " 'hphob_breese',\n",
       " 'hphob_fauchere',\n",
       " 'hphob_guy',\n",
       " 'hphob_janin',\n",
       " 'hphob_miyazawa',\n",
       " 'hphob_argos',\n",
       " 'hphob_roseman',\n",
       " 'hphob_tanford',\n",
       " 'hphob_wolfenden',\n",
       " 'hphob_welling',\n",
       " 'hphob_wilson',\n",
       " 'hphob_parker',\n",
       " 'hphob_ph3_4',\n",
       " 'hphob_ph7_5',\n",
       " 'hphob_mobility',\n",
       " 'hplchfba',\n",
       " 'hplctfa',\n",
       " 'transmembranetendency',\n",
       " 'hplc2_1',\n",
       " 'hplc7_4',\n",
       " 'buriedresidues',\n",
       " 'accessibleresidues',\n",
       " 'hphob_chothia',\n",
       " 'hphob_rose',\n",
       " 'ratioside',\n",
       " 'averageburied',\n",
       " 'averageflexibility',\n",
       " 'alpha_helixfasman',\n",
       " 'beta_sheetfasman',\n",
       " 'beta_turnfasman',\n",
       " 'alpha_helixroux',\n",
       " 'beta_sheetroux',\n",
       " 'beta_turnroux',\n",
       " 'coilroux',\n",
       " 'alpha_helixlevitt',\n",
       " 'beta_sheetlevitt',\n",
       " 'beta_turnlevitt',\n",
       " 'totalbeta_strand',\n",
       " 'antiparallelbeta_strand',\n",
       " 'parallelbeta_strand',\n",
       " 'a_a_composition',\n",
       " 'a_a_swiss_prot',\n",
       " 'relativemutability',\n",
       " 'hbond_acc',\n",
       " 'hbond_donor',\n",
       " 'meiler0',\n",
       " 'meiler1',\n",
       " 'meiler2',\n",
       " 'meiler3',\n",
       " 'meiler4',\n",
       " 'meiler5',\n",
       " 'meiler6',\n",
       " 'sidechain_vector0',\n",
       " 'sidechain_vector1',\n",
       " 'sidechain_vector2',\n",
       " 'c_beta_vector0',\n",
       " 'c_beta_vector1',\n",
       " 'c_beta_vector2',\n",
       " 'sequence_neighbour_vector_n_to_c0',\n",
       " 'sequence_neighbour_vector_n_to_c1',\n",
       " 'sequence_neighbour_vector_n_to_c2',\n",
       " 'ASAquick_normscore',\n",
       " 'DFLpredScore',\n",
       " 'DRNApredDNAscore',\n",
       " 'DRNApredRNAscore',\n",
       " 'DisoDNAscore',\n",
       " 'DisoPROscore',\n",
       " 'DisoRNAscore',\n",
       " 'MMseq2_conservation_score',\n",
       " 'MoRFchibiScore',\n",
       " 'PSIPRED_helix',\n",
       " 'PSIPRED_strand',\n",
       " 'SCRIBERscore',\n",
       " 'flDPnn_score',\n",
       " 'PTMbinary',\n",
       " 'ACT_SITE',\n",
       " 'BINDING',\n",
       " 'DNA_BIND',\n",
       " 'TOPO_DOM',\n",
       " 'TRANSMEM',\n",
       " 'DISULFID',\n",
       " 'PROPEP',\n",
       " 'SIGNAL',\n",
       " 'TRANSIT',\n",
       " 'STRAND',\n",
       " 'HELIX',\n",
       " 'COILED',\n",
       " 'COMPBIAS',\n",
       " 'DOMAIN',\n",
       " 'REGION',\n",
       " 'REPEAT',\n",
       " 'ZN_FING',\n",
       " 'phyloP100way_vertebrate',\n",
       " 'phyloP30way_mammalian']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep names for features \n",
    "\n",
    "temp_g = construct_graph(config=config, path=(af_db_path + prefix + \"P49588\" + suffix))\n",
    "\n",
    "# AA onehot 20\n",
    "all_feature_names = [\"aa\"+str(i) for i in range(20)]\n",
    "\n",
    "# expasy 61\n",
    "for n, d in temp_g.nodes(data=True):\n",
    "    all_feature_names += d[\"expasy\"].index.values.tolist()\n",
    "    break\n",
    "\n",
    "# hbond acceptor and donor\n",
    "all_feature_names += [\"hbond_acc\", \"hbond_donor\"]\n",
    "\n",
    "# meiler\n",
    "all_feature_names += [\"meiler\"+str(i) for i in range(7)]\n",
    "\n",
    "# sidechain_vector\n",
    "all_feature_names += [\"sidechain_vector\"+str(i) for i in range(3)]\n",
    "\n",
    "# c_beta_vector\n",
    "all_feature_names += [\"c_beta_vector\"+str(i) for i in range(3)]\n",
    "\n",
    "# sequence_neighbour_vector_n_to_c\n",
    "all_feature_names += [\"sequence_neighbour_vector_n_to_c\"+str(i) for i in range(3)]\n",
    "\n",
    "# describeProt\n",
    "all_feature_names += describe_prot_featnames.tolist()\n",
    "\n",
    "# UniProt\n",
    "all_feature_names += uniprot_features\n",
    "\n",
    "# Phylop\n",
    "all_feature_names += phylop_features\n",
    "\n",
    "# protLM embeddings \n",
    "#all_feature_names += [\"protLM\"+str(i) for i in range(1024)]\n",
    "\n",
    "all_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4df8aa0-4144-40d1-b0db-7ef0f6629714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa0',\n",
       " 'aa1',\n",
       " 'aa2',\n",
       " 'aa3',\n",
       " 'aa4',\n",
       " 'aa5',\n",
       " 'aa6',\n",
       " 'aa7',\n",
       " 'aa8',\n",
       " 'aa9',\n",
       " 'aa10',\n",
       " 'aa11',\n",
       " 'aa12',\n",
       " 'aa13',\n",
       " 'aa14',\n",
       " 'aa15',\n",
       " 'aa16',\n",
       " 'aa17',\n",
       " 'aa18',\n",
       " 'aa19',\n",
       " 'ACT_SITE',\n",
       " 'BINDING',\n",
       " 'DNA_BIND',\n",
       " 'TOPO_DOM',\n",
       " 'DISULFID',\n",
       " 'PROPEP',\n",
       " 'SIGNAL',\n",
       " 'TRANSIT',\n",
       " 'STRAND',\n",
       " 'HELIX',\n",
       " 'COILED',\n",
       " 'COMPBIAS',\n",
       " 'DOMAIN',\n",
       " 'REGION',\n",
       " 'REPEAT',\n",
       " 'ZN_FING',\n",
       " 'MMseq2_conservation_score',\n",
       " 'PSIPRED_helix',\n",
       " 'PSIPRED_strand',\n",
       " 'PTMbinary',\n",
       " 'a_a_composition',\n",
       " 'accessibleresidues',\n",
       " 'antiparallelbeta_strand',\n",
       " 'averageburied',\n",
       " 'beta_turnfasman',\n",
       " 'bulkiness',\n",
       " 'buriedresidues',\n",
       " 'c_beta_vector0',\n",
       " 'c_beta_vector1',\n",
       " 'c_beta_vector2',\n",
       " 'hbond_acc',\n",
       " 'hbond_donor',\n",
       " 'hphob_welling',\n",
       " 'isoelectric_points',\n",
       " 'numbercodons',\n",
       " 'pka_nh3',\n",
       " 'ratioside',\n",
       " 'recognitionfactors',\n",
       " 'relativemutability',\n",
       " 'sequence_neighbour_vector_n_to_c0',\n",
       " 'sequence_neighbour_vector_n_to_c1',\n",
       " 'sequence_neighbour_vector_n_to_c2']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Step 1: Concatenate all graph features\n",
    "# Assuming `all_feature_names` corresponds to columns in the node feature matrix `x`\n",
    "def concatenate_graph_features(graphs):\n",
    "    feature_list = []\n",
    "    for graph in graphs:\n",
    "        feature_list.append(graph.x)\n",
    "    return torch.cat(feature_list, dim=0)\n",
    "\n",
    "# Assuming `graphs` is the list of Data objects\n",
    "concatenated_features = concatenate_graph_features(train_list_norm)\n",
    "\n",
    "# sample 10k amino acids\n",
    "concatenated_features = concatenated_features[torch.randperm(concatenated_features.size(0))[:10_000]]\n",
    "\n",
    "# Convert to pandas DataFrame for easier manipulation\n",
    "df_features = pd.DataFrame(concatenated_features.numpy(), columns=all_feature_names)\n",
    "\n",
    "# Step 2: Remove features with low variance (except for binary features)\n",
    "# Identify binary features (one-hot encoded)\n",
    "binary_columns = df_features.columns[df_features.nunique() == 2]\n",
    "non_binary_columns = df_features.columns.difference(binary_columns)\n",
    "\n",
    "# Apply variance thresholding on non-binary features\n",
    "selector = VarianceThreshold(threshold=0.1)\n",
    "filtered_features = selector.fit_transform(df_features[non_binary_columns])\n",
    "\n",
    "# Keep the selected features\n",
    "selected_features = non_binary_columns[selector.get_support()]\n",
    "\n",
    "# Combine back with binary columns that were not filtered\n",
    "df_filtered = pd.concat([df_features[binary_columns], df_features[selected_features]], axis=1)\n",
    "\n",
    "# Step 3: Remove highly correlated features\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_filtered.corr().abs()\n",
    "\n",
    "# Identify highly correlated features (correlation > 0.8)\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Select columns to drop based on the correlation threshold\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.8)]\n",
    "\n",
    "# Drop the highly correlated features\n",
    "df_final = df_filtered.drop(columns=to_drop)\n",
    "\n",
    "# Step 4: Update all_feature_names\n",
    "all_feature_names_filtered = df_final.columns.tolist()\n",
    "\n",
    "all_feature_names_filtered  # Updated feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6de2bb55-3e63-4086-b3c0-e1b6040930b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 106,\n",
       " 108,\n",
       " 109,\n",
       " 112,\n",
       " 78,\n",
       " 59,\n",
       " 76,\n",
       " 63,\n",
       " 67,\n",
       " 26,\n",
       " 58,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 81,\n",
       " 82,\n",
       " 47,\n",
       " 23,\n",
       " 25,\n",
       " 21,\n",
       " 62,\n",
       " 30,\n",
       " 80,\n",
       " 96,\n",
       " 97,\n",
       " 98]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feat_indexes = [all_feature_names.index(item) for item in all_feature_names_filtered]\n",
    "\n",
    "selected_feat_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ce24748d-48f1-49b4-8aad-0ea4a1c51202",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_list_norm)):\n",
    "    train_list_norm[i].x = train_list_norm[i].x[:, selected_feat_indexes]\n",
    "\n",
    "for i in range(len(test_list_norm)):\n",
    "    test_list_norm[i].x = test_list_norm[i].x[:, selected_feat_indexes]\n",
    "\n",
    "for i in range(len(val_list_norm)):\n",
    "    val_list_norm[i].x = val_list_norm[i].x[:, selected_feat_indexes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6796195-f637-4db9-8ba6-e446c01585a3",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a00a2291-dcc2-48e2-85d6-04be1a576458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=0.8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=0.8)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Concatenate node features from all graphs in train_list\n",
    "all_train_features = torch.cat([graph.x for graph in train_list_norm], dim=0)\n",
    "\n",
    "# Fit PCA on the concatenated features\n",
    "#pca = PCA(n_components=64)  # Specify the number of components\n",
    "pca = PCA(n_components=0.8) \n",
    "pca.fit(all_train_features.numpy())  # Convert to numpy for PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "19e795e2-9575-4fe8-8917-098671c3a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Function to apply PCA to the node features of a list of graphs\n",
    "def apply_pca(graph_list, pca_model):\n",
    "    for graph in graph_list:\n",
    "        graph.x = torch.tensor(pca_model.transform(graph.x.numpy()), dtype=torch.float)\n",
    "\n",
    "#make_copy \n",
    "train_list_norm_pca = copy.deepcopy(train_list_norm)\n",
    "val_list_norm_pca = copy.deepcopy(val_list_norm)\n",
    "test_list_norm_pca = copy.deepcopy(test_list_norm)\n",
    "\n",
    "# Apply PCA to train, val, and test lists\n",
    "apply_pca(train_list_norm_pca, pca)\n",
    "apply_pca(val_list_norm_pca, pca)\n",
    "apply_pca(test_list_norm_pca, pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c0346-12d0-4f43-b7c1-723d1a42cab0",
   "metadata": {},
   "source": [
    "### Define a GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a5030964-6750-4ced-ba19-ff31c65cac19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "train_loader_nopca = DataLoader(train_list_norm, batch_size=batch_size, shuffle=True)\n",
    "test_loader_nopca = DataLoader(test_list_norm, batch_size=batch_size, shuffle=True)\n",
    "val_loader_nopca = DataLoader(val_list_norm, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_loader_pca = DataLoader(train_list_norm_pca, batch_size=batch_size, shuffle=True)\n",
    "test_loader_pca = DataLoader(test_list_norm_pca, batch_size=batch_size, shuffle=True)\n",
    "val_loader_pca = DataLoader(val_list_norm_pca, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cfbbb24d-6956-4592-9c7b-bae90f58afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU\n",
    "from torch_geometric.nn import GINConv, GATv2Conv, GCNConv, global_add_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    \"\"\"GNN model for multi-label classification\"\"\"\n",
    "    def __init__(self, arch, dim_in, dim_h, dim_out, dim_graph_feature, n_layer=2, heads=2, use_graph_feat=False, dropout_p=0.5):\n",
    "        super(GNN, self).__init__()\n",
    "        # Store the initialization arguments\n",
    "        self.args = (arch, dim_in, dim_h, dim_out, dim_graph_feature, n_layer, heads, use_graph_feat, dropout_p)\n",
    "        self.use_graph_feat = use_graph_feat\n",
    "        self.dropout_p = dropout_p\n",
    "        self.n_layer = n_layer\n",
    "        self.heads = heads\n",
    "\n",
    "        # Initialize hidden_dims: divide hidden dimensions by 2 after each layer\n",
    "        hidden_dims = [dim_h]  # Start with the input hidden dimension\n",
    "        for i in range(1, n_layer):\n",
    "            hidden_dims.append(hidden_dims[-1] // 2)  # Divide by 2 progressively\n",
    "\n",
    "        if arch == \"GCN\":\n",
    "            self.convs = torch.nn.ModuleList([GCNConv(dim_in if i == 0 else hidden_dims[i-1], hidden_dims[i]) for i in range(n_layer)])\n",
    "\n",
    "        elif arch == \"GAT\":\n",
    "            self.convs = torch.nn.ModuleList([\n",
    "                GATv2Conv(dim_in if i == 0 else hidden_dims[i-1] * heads, hidden_dims[i], heads=heads, concat=True)\n",
    "                for i in range(n_layer)\n",
    "            ])\n",
    "\n",
    "        elif arch == \"GIN\":\n",
    "            self.convs = torch.nn.ModuleList([\n",
    "                GINConv(\n",
    "                    Sequential(Linear(dim_in if i == 0 else hidden_dims[i-1], hidden_dims[i]),\n",
    "                               BatchNorm1d(hidden_dims[i]), ReLU(),\n",
    "                               Linear(hidden_dims[i], hidden_dims[i]), ReLU())\n",
    "                )\n",
    "                for i in range(n_layer)\n",
    "            ])\n",
    "\n",
    "        # Calculate total input dimension for lin1 based on the number of layers and heads (if applicable)\n",
    "        if arch == \"GAT\":\n",
    "            total_dim = sum([dim * heads for dim in hidden_dims])\n",
    "        else:\n",
    "            total_dim = sum(hidden_dims)\n",
    "\n",
    "        if self.use_graph_feat:\n",
    "            total_dim += dim_graph_feature  # Include graph features if applicable\n",
    "\n",
    "        self.lin1 = Linear(total_dim, dim_h * n_layer)  # Adjusted lin1 to match the total dimension\n",
    "        self.lin2 = Linear(dim_h * n_layer, dim_out)    # Output layer for multi-label prediction\n",
    "\n",
    "    def forward(self, x, edge_index, batch, graph_features):\n",
    "        # x, edge_index, batch, graph_features = data.x, data.edge_index, data.batch, data.u\n",
    "\n",
    "        h_list = []\n",
    "        h = x\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index)\n",
    "            h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "            h_list.append(global_add_pool(h, batch))\n",
    "\n",
    "        # Concatenate graph embeddings from each layer\n",
    "        h = torch.cat(h_list, dim=1)\n",
    "\n",
    "        if self.use_graph_feat:\n",
    "            # Concatenate graph-level features to the pooled graph embeddings\n",
    "            graph_features = graph_features.reshape(h.shape[0], -1)\n",
    "            h = torch.cat((h, graph_features), dim=1)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=self.dropout_p, training=self.training)  # Dropout for regularization\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        return h  # Returning raw logits for BCEWithLogitsLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1071016-2e1a-4609-b456-232c2039d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "def calculate_metrics(logits, target, threshold=0.5):\n",
    "    # Convert logits to probabilities using sigmoid\n",
    "    probs = torch.sigmoid(logits)\n",
    "    \n",
    "    # Convert probabilities to binary predictions (threshold 0.5)\n",
    "    pred = (probs > threshold).float()  # Binary predictions\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    target_np = target.cpu().numpy()\n",
    "\n",
    "    # F1 Score\n",
    "    f1_per_class = f1_score(target_np, pred_np, average=None, zero_division=0) # (Per class)\n",
    "    f1_micro = f1_score(target_np, pred_np, average='micro', zero_division=0)\n",
    "    f1_macro = f1_score(target_np, pred_np, average='macro', zero_division=0) \n",
    "    \n",
    "    # Precision and Recall\n",
    "    precision_per_class = precision_score(target_np, pred_np, average=None, zero_division=0)\n",
    "    precision_micro = precision_score(target_np, pred_np, average='micro', zero_division=0)\n",
    "    precision_macro = precision_score(target_np, pred_np, average='macro', zero_division=0) \n",
    "    \n",
    "    recall_per_class = recall_score(target_np, pred_np, average=None, zero_division=0)\n",
    "    recall_micro = recall_score(target_np, pred_np, average='micro', zero_division=0)\n",
    "    recall_macro = recall_score(target_np, pred_np, average='macro', zero_division=0) \n",
    "\n",
    "    # Matthews Correlation Coefficient (MCC) per class\n",
    "    class_mccs = []\n",
    "    for i in range(target_np.shape[1]):  # Iterate over each class (column in multi-label)\n",
    "        class_mcc = matthews_corrcoef(target_np[:, i], pred_np[:, i])\n",
    "        class_mccs.append(class_mcc)\n",
    "        \n",
    "    # MCC for the entire dataset (flattened)\n",
    "    mcc_overall = matthews_corrcoef(target_np.ravel(), pred_np.ravel())\n",
    "    \n",
    "    return {\n",
    "        'f1_per_class': f1_per_class,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_per_class': precision_per_class,\n",
    "        'precision_micro': precision_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_per_class': recall_per_class,\n",
    "        'recall_micro': recall_micro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'mcc_per_class': class_mccs,\n",
    "        'mcc_overall': mcc_overall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d6970cd9-1065-4cfa-870a-a677bd2a7e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2822, 0.9405, 1.3732])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 3  # Number of classes in the multi-label setting\n",
    "\n",
    "# Initialize counters for positive and negative labels\n",
    "positive_counts = torch.zeros(num_classes)\n",
    "negative_counts = torch.zeros(num_classes)\n",
    "\n",
    "# Loop through each graph and count positives and negatives\n",
    "for graph in train_list_norm:\n",
    "    label = torch.tensor(graph.y)  # Assume graph.y is a tensor of shape [3] for the label [1, 1, 0]\n",
    "    \n",
    "    positive_counts += (label == 1).float()  # Count positives (1s)\n",
    "    negative_counts += (label == 0).float()  # Count negatives (0s)\n",
    "\n",
    "# Calculate the pos_weight for each class\n",
    "pos_weight = negative_counts / positive_counts\n",
    "pos_weight = pos_weight.to(torch.float32)\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "919ba615-6f14-4bec-9543-72ae3891b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        \"\"\"\n",
    "        :param alpha: balancing factor between classes (for class imbalance)\n",
    "        :param gamma: focusing parameter to focus on hard examples\n",
    "        :param reduction: reduction method, either 'mean', 'sum', or 'none'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Convert targets to one-hot encoding if needed\n",
    "        if inputs.dim() > 2:\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "            inputs = inputs.transpose(1, 2)\n",
    "            inputs = inputs.contiguous().view(-1, inputs.size(-1))\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # pt is the predicted probability for the true class\n",
    "\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1b46bdd3-2566-456a-91e6-4de0ffb8abd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nimport torch.nn.functional as F\\n\\nclass FocalMCCLoss(torch.nn.Module):\\n    def __init__(self, alpha=1, gamma=2, lambda_mcc=0.5, reduction=\\'mean\\'):\\n        \"\"\"\\n        :param alpha: balancing factor for Focal Loss\\n        :param gamma: focusing parameter for Focal Loss\\n        :param lambda_mcc: weight for MCC Loss\\n        :param reduction: reduction method, \\'mean\\', \\'sum\\', or \\'none\\'\\n        \"\"\"\\n        super(FocalMCCLoss, self).__init__()\\n        self.alpha = alpha\\n        self.gamma = gamma\\n        self.lambda_mcc = lambda_mcc\\n        self.reduction = reduction\\n\\n    def focal_loss(self, inputs, targets):\\n        # Convert targets to one-hot encoding if needed\\n        if inputs.dim() > 2:\\n            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)\\n            inputs = inputs.transpose(1, 2)\\n            inputs = inputs.contiguous().view(-1, inputs.size(-1))\\n            targets = targets.view(-1)\\n\\n        BCE_loss = F.cross_entropy(inputs, targets, reduction=\\'none\\')\\n        pt = torch.exp(-BCE_loss)  # pt is the predicted probability for the true class\\n\\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\\n\\n        if self.reduction == \\'mean\\':\\n            return torch.mean(focal_loss)\\n        elif self.reduction == \\'sum\\':\\n            return torch.sum(focal_loss)\\n        else:\\n            return focal_loss\\n\\n    def mcc_loss(self, preds, targets):\\n        \"\"\"\\n        MCC Loss, similar to the function defined above.\\n        Computes the MCC-based loss.\\n        \"\"\"\\n        preds = preds.sigmoid()  # Apply sigmoid if inputs are logits\\n        preds = preds.view(-1)\\n        targets = targets.view(-1)\\n\\n        tp = (preds * targets).sum()  # True positives\\n        tn = ((1 - preds) * (1 - targets)).sum()  # True negatives\\n        fp = (preds * (1 - targets)).sum()  # False positives\\n        fn = ((1 - preds) * targets).sum()  # False negatives\\n\\n        numerator = (tp * tn - fp * fn)\\n        denominator = torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\\n\\n        # To avoid division by zero\\n        denominator = torch.clamp(denominator, min=1e-6)\\n\\n        mcc = numerator / denominator\\n        return 1 - mcc  # Return negative MCC (because we want to maximize MCC)\\n\\n    def forward(self, inputs, targets):\\n        \"\"\"\\n        Combined Focal and MCC Loss.\\n        \"\"\"\\n        focal_loss = self.focal_loss(inputs, targets)\\n        mcc_loss = self.mcc_loss(inputs, targets)\\n        \\n        # Weighted combination of the two losses\\n        combined_loss = focal_loss + self.lambda_mcc * mcc_loss\\n        \\n        return combined_loss\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalMCCLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, lambda_mcc=0.5, reduction='mean'):\n",
    "        \"\"\"\n",
    "        :param alpha: balancing factor for Focal Loss\n",
    "        :param gamma: focusing parameter for Focal Loss\n",
    "        :param lambda_mcc: weight for MCC Loss\n",
    "        :param reduction: reduction method, 'mean', 'sum', or 'none'\n",
    "        \"\"\"\n",
    "        super(FocalMCCLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.lambda_mcc = lambda_mcc\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def focal_loss(self, inputs, targets):\n",
    "        # Convert targets to one-hot encoding if needed\n",
    "        if inputs.dim() > 2:\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "            inputs = inputs.transpose(1, 2)\n",
    "            inputs = inputs.contiguous().view(-1, inputs.size(-1))\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # pt is the predicted probability for the true class\n",
    "\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "    def mcc_loss(self, preds, targets):\n",
    "        \"\"\"\n",
    "        MCC Loss, similar to the function defined above.\n",
    "        Computes the MCC-based loss.\n",
    "        \"\"\"\n",
    "        preds = preds.sigmoid()  # Apply sigmoid if inputs are logits\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        tp = (preds * targets).sum()  # True positives\n",
    "        tn = ((1 - preds) * (1 - targets)).sum()  # True negatives\n",
    "        fp = (preds * (1 - targets)).sum()  # False positives\n",
    "        fn = ((1 - preds) * targets).sum()  # False negatives\n",
    "\n",
    "        numerator = (tp * tn - fp * fn)\n",
    "        denominator = torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "        # To avoid division by zero\n",
    "        denominator = torch.clamp(denominator, min=1e-6)\n",
    "\n",
    "        mcc = numerator / denominator\n",
    "        return 1 - mcc  # Return negative MCC (because we want to maximize MCC)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Combined Focal and MCC Loss.\n",
    "        \"\"\"\n",
    "        focal_loss = self.focal_loss(inputs, targets)\n",
    "        mcc_loss = self.mcc_loss(inputs, targets)\n",
    "        \n",
    "        # Weighted combination of the two losses\n",
    "        combined_loss = focal_loss + self.lambda_mcc * mcc_loss\n",
    "        \n",
    "        return combined_loss\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19764512-187e-4472-aa98-a085f23b3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training parameters\n",
    "input_dim_nopca = train_list_norm[0].x.shape[1]  # Adjust this based on your feature size\n",
    "input_dim_pca = train_list_norm_pca[0].x.shape[1]  # Adjust this based on your feature size\n",
    "hidden_dim = 64\n",
    "output_dim = 1  # Number of labels\n",
    "n_layer = 2\n",
    "graph_features_dim = train_list_norm[0].u.shape[1]\n",
    "\n",
    "# define potential models\n",
    "gcn_pca   = GNN(\"GCN\", input_dim_pca, hidden_dim, output_dim, graph_features_dim, n_layer=n_layer, use_graph_feat=True).to(device)\n",
    "gcn_nopca = GNN(\"GCN\", input_dim_nopca, hidden_dim, output_dim, graph_features_dim, n_layer=n_layer, use_graph_feat=True).to(device)\n",
    "\n",
    "gat_pca   = GNN(\"GAT\", input_dim_pca, hidden_dim, output_dim, graph_features_dim, n_layer=n_layer, heads=1, use_graph_feat=True).to(device)\n",
    "gat_nopca = GNN(\"GAT\", input_dim_nopca, hidden_dim, output_dim, graph_features_dim, n_layer=n_layer, heads=1, use_graph_feat=True).to(device)\n",
    "\n",
    "gin_pca   = GNN(\"GIN\", input_dim_pca, hidden_dim, output_dim, graph_features_dim, n_layer=n_layer, use_graph_feat=True).to(device)\n",
    "gin_nopca = GNN(\"GIN\", input_dim_nopca, hidden_dim, output_dim, graph_features_dim, n_layer=n_layer, use_graph_feat=True).to(device)\n",
    "\n",
    "LR = 5e-4\n",
    "WD = 5e-4\n",
    "# define optimizers\n",
    "opt_gcn_pca = torch.optim.AdamW(gcn_pca.parameters(), lr=LR, weight_decay=WD)\n",
    "opt_gcn_nopca = torch.optim.AdamW(gcn_nopca.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "opt_gat_pca = torch.optim.AdamW(gat_pca.parameters(), lr=LR, weight_decay=WD)\n",
    "opt_gat_nopca = torch.optim.AdamW(gat_nopca.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "opt_gin_pca = torch.optim.AdamW(gin_pca.parameters(), lr=LR, weight_decay=WD)\n",
    "opt_gin_nopca = torch.optim.AdamW(gin_nopca.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "# define schedulers\n",
    "scheduler_gcn_pca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_gcn_pca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "scheduler_gcn_nopca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_gcn_nopca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "scheduler_gat_pca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_gat_pca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "scheduler_gat_nopca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_gat_nopca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "scheduler_gin_pca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_gin_pca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "scheduler_gin_nopca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_gin_nopca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "# define loss\n",
    "#criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "#criterion = FocalMCCLoss(lambda_mcc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e353cf93-a8b6-4171-a507-dec8c0564c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, model_arch, scheduler=None, epochs=100, patience=5, y_index=0):\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "    best_model_wts = None  # Variable to store the best model weights\n",
    "    patience_counter = 0  # Counter for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        all_train_preds = []\n",
    "        all_train_targets = []\n",
    "        \n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Ensure input features are in float32\n",
    "            data.x = data.x.float()\n",
    "            \n",
    "            # If data.y is a list, convert it to a tensor, then cast to float32\n",
    "            if isinstance(data.y, list):\n",
    "                data.y = torch.tensor(data.y, dtype=torch.float32).to(device)[:,y_index].reshape(-1,1)\n",
    "            else:\n",
    "                data.y = data.y.float()[:,y_index].reshape(-1,1)  # Otherwise, cast directly\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            if model_arch == \"EGNN\":\n",
    "                out = model(data.x, data.edge_index, data.coords.float(), data.batch)\n",
    "            else:\n",
    "                out = model(data.x, data.edge_index, data.batch, data.u)\n",
    "\n",
    "            \n",
    "            loss = criterion(out, data.y)  # Multi-label target\n",
    "            loss.backward()\n",
    "            total_train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            all_train_preds.append(out.detach())\n",
    "            all_train_targets.append(data.y)\n",
    "        \n",
    "        all_train_preds = torch.cat(all_train_preds, dim=0)\n",
    "        all_train_targets = torch.cat(all_train_targets, dim=0)\n",
    "        \n",
    "        # Calculate metrics for train\n",
    "        train_metrics = calculate_metrics(all_train_preds, all_train_targets)\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_metrics = evaluate(model, val_loader, model_arch, y_index)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.3f}, Train metrics: {train_metrics}')\n",
    "        print(f'            Val Loss:   {val_loss:.3f}, Val F1:   {val_metrics}')\n",
    "        print('*****')\n",
    "        \n",
    "        # Check if validation loss has improved\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f'Validation loss decreased ({best_val_loss:.4f} -> {val_loss:.4f}). Saving model...')\n",
    "            best_val_loss = val_loss\n",
    "            # Save both model state and arguments used to create it\n",
    "            best_model_wts = {\n",
    "                'state_dict': model.state_dict(),\n",
    "                'args': model.args  # Save initialization arguments\n",
    "            }\n",
    "            patience_counter = 0  # Reset patience counter when improvement occurs\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'No improvement for {patience_counter} epochs.')\n",
    "\n",
    "        # Early stopping: stop if no improvement for 'patience' number of epochs\n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered after {patience_counter} epochs without improvement.')\n",
    "            break\n",
    "\n",
    "        # Step the learning rate scheduler (if provided)\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            print(f\"Learning rate adjusted: {scheduler.get_last_lr()}\")\n",
    "    \n",
    "    # Load the best model weights at the end of training\n",
    "    if best_model_wts is not None:\n",
    "        # Step 1: Create a new instance of the same model class with saved args\n",
    "        copied_model = model.__class__(*best_model_wts['args'])  # Use saved args\n",
    "        \n",
    "        # Step 2: Load the state_dict of the original model into the copied model\n",
    "        copied_model.load_state_dict(best_model_wts['state_dict'])\n",
    "\n",
    "        # Step 3: Move the copied model to the same device as the original model (if you're using GPU)\n",
    "        copied_model = copied_model.to(next(model.parameters()).device)\n",
    "    \n",
    "    return copied_model\n",
    "\n",
    "\n",
    "# Evaluation loop remains the same\n",
    "def evaluate(model, loader, model_arch, threshold=0.5, y_index=0):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Ensure input features are in float32\n",
    "            data.x = data.x.float()\n",
    "            \n",
    "            # If data.y is a list, convert it to a tensor, then cast to float32\n",
    "            if isinstance(data.y, list):\n",
    "                data.y = torch.tensor(data.y, dtype=torch.float32).to(device)[:,y_index].reshape(-1,1)\n",
    "            else:\n",
    "                data.y = data.y.float()[:,y_index].reshape(-1,1)  # Otherwise, cast directly\n",
    "\n",
    "            if model_arch == \"EGNN\":\n",
    "                out = model(data.x, data.edge_index, data.coords.float(), data.batch)\n",
    "            else:\n",
    "                out = model(data.x, data.edge_index, data.batch, data.u)\n",
    "   \n",
    "            \n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_preds.append(out)\n",
    "            all_targets.append(data.y)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    \n",
    "    # Calculate metrics for validation\n",
    "    metrics = calculate_metrics(all_preds, all_targets, threshold)\n",
    "    \n",
    "    return total_loss / len(loader), metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b2e19d02-7eaa-4338-b059-0092864c87cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# GCN PCA\\ntrained_gcn_pca = train(gcn_pca, opt_gcn_pca, train_loader_pca, val_loader_pca, model_arch=\"GCN\", scheduler=scheduler_gcn_pca, epochs=100)\\nprint(\"\\nBest model:\")\\ntrained_gcn_pca.eval()\\nval_loss, val_metrics = evaluate(trained_gcn_pca, test_loader_pca, model_arch=\"GCN\")\\nval_loss, val_metrics\\n'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# GCN PCA\n",
    "trained_gcn_pca = train(gcn_pca, opt_gcn_pca, train_loader_pca, val_loader_pca, model_arch=\"GCN\", scheduler=scheduler_gcn_pca, epochs=100)\n",
    "print(\"\\nBest model:\")\n",
    "trained_gcn_pca.eval()\n",
    "val_loss, val_metrics = evaluate(trained_gcn_pca, test_loader_pca, model_arch=\"GCN\")\n",
    "val_loss, val_metrics\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3ce2cb16-66c6-4e65-929d-c9e361cec3a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.000, Train metrics: {'f1_per_class': array([0.13015873, 0.60632184]), 'f1_micro': 0.4579624134520277, 'f1_macro': 0.36824028461959496, 'precision_per_class': array([0.66129032, 0.44467861]), 'precision_micro': 0.4579624134520277, 'precision_macro': 0.5529844658214079, 'recall_per_class': array([0.0721831 , 0.95259594]), 'recall_micro': 0.4579624134520277, 'recall_macro': 0.5123895176930658, 'mcc_per_class': [0.051242637588319984], 'mcc_overall': 0.051242637588319984}\n",
      "            Val Loss:   0.000, Val F1:   {'f1_per_class': array([0.        , 0.60773481]), 'f1_micro': 0.4365079365079365, 'f1_macro': 0.30386740331491713, 'precision_per_class': array([0.        , 0.43650794]), 'precision_micro': 0.4365079365079365, 'precision_macro': 0.21825396825396826, 'recall_per_class': array([0., 1.]), 'recall_micro': 0.4365079365079365, 'recall_macro': 0.5, 'mcc_per_class': [0.0], 'mcc_overall': 0.0}\n",
      "*****\n",
      "Validation loss decreased (inf -> 0.0000). Saving model...\n",
      "Epoch 2, Train Loss: 0.000, Train metrics: {'f1_per_class': array([0.10675039, 0.58916968]), 'f1_micro': 0.437190900098912, 'f1_macro': 0.3479600337774655, 'precision_per_class': array([0.49275362, 0.43312102]), 'precision_micro': 0.437190900098912, 'precision_macro': 0.4629373211483431, 'recall_per_class': array([0.05985915, 0.92099323]), 'recall_micro': 0.437190900098912, 'recall_macro': 0.49042619146027405, 'mcc_per_class': [-0.03767391624427243], 'mcc_overall': -0.03767391624427243}\n",
      "            Val Loss:   0.000, Val F1:   {'f1_per_class': array([0.        , 0.60773481]), 'f1_micro': 0.4365079365079365, 'f1_macro': 0.30386740331491713, 'precision_per_class': array([0.        , 0.43650794]), 'precision_micro': 0.4365079365079365, 'precision_macro': 0.21825396825396826, 'recall_per_class': array([0., 1.]), 'recall_micro': 0.4365079365079365, 'recall_macro': 0.5, 'mcc_per_class': [0.0], 'mcc_overall': 0.0}\n",
      "*****\n",
      "No improvement for 1 epochs.\n",
      "Epoch 3, Train Loss: 0.000, Train metrics: {'f1_per_class': array([0.12578616, 0.5988456 ]), 'f1_micro': 0.45004945598417406, 'f1_macro': 0.3623158811838057, 'precision_per_class': array([0.58823529, 0.44008484]), 'precision_micro': 0.45004945598417406, 'precision_macro': 0.5141600648743061, 'recall_per_class': array([0.07042254, 0.93679458]), 'recall_micro': 0.45004945598417406, 'recall_macro': 0.503608558802022, 'mcc_per_class': [0.014296492820182227], 'mcc_overall': 0.014296492820182227}\n",
      "            Val Loss:   0.000, Val F1:   {'f1_per_class': array([0.        , 0.60773481]), 'f1_micro': 0.4365079365079365, 'f1_macro': 0.30386740331491713, 'precision_per_class': array([0.        , 0.43650794]), 'precision_micro': 0.4365079365079365, 'precision_macro': 0.21825396825396826, 'recall_per_class': array([0., 1.]), 'recall_micro': 0.4365079365079365, 'recall_macro': 0.5, 'mcc_per_class': [0.0], 'mcc_overall': 0.0}\n",
      "*****\n",
      "No improvement for 2 epochs.\n",
      "Epoch 4, Train Loss: 0.000, Train metrics: {'f1_per_class': array([0.09951846, 0.59899929]), 'f1_micro': 0.44510385756676557, 'f1_macro': 0.3492588721363689, 'precision_per_class': array([0.56363636, 0.43828452]), 'precision_micro': 0.44510385756676557, 'precision_macro': 0.5009604412324078, 'recall_per_class': array([0.05457746, 0.94582393]), 'recall_micro': 0.44510385756676557, 'recall_macro': 0.5002006962769847, 'mcc_per_class': [0.0008780819542772562], 'mcc_overall': 0.0008780819542772562}\n",
      "            Val Loss:   0.000, Val F1:   {'f1_per_class': array([0.        , 0.60773481]), 'f1_micro': 0.4365079365079365, 'f1_macro': 0.30386740331491713, 'precision_per_class': array([0.        , 0.43650794]), 'precision_micro': 0.4365079365079365, 'precision_macro': 0.21825396825396826, 'recall_per_class': array([0., 1.]), 'recall_micro': 0.4365079365079365, 'recall_macro': 0.5, 'mcc_per_class': [0.0], 'mcc_overall': 0.0}\n",
      "*****\n",
      "No improvement for 3 epochs.\n",
      "Epoch 5, Train Loss: 0.000, Train metrics: {'f1_per_class': array([0.10691824, 0.59018759]), 'f1_micro': 0.4381800197823937, 'f1_macro': 0.3485529145906504, 'precision_per_class': array([0.5       , 0.43372216]), 'precision_micro': 0.4381800197823937, 'precision_macro': 0.4668610816542948, 'recall_per_class': array([0.05985915, 0.92325056]), 'recall_micro': 0.4381800197823937, 'recall_macro': 0.49155485963183165, 'mcc_per_class': [-0.03345820180934717], 'mcc_overall': -0.03345820180934717}\n",
      "            Val Loss:   0.000, Val F1:   {'f1_per_class': array([0.        , 0.60773481]), 'f1_micro': 0.4365079365079365, 'f1_macro': 0.30386740331491713, 'precision_per_class': array([0.        , 0.43650794]), 'precision_micro': 0.4365079365079365, 'precision_macro': 0.21825396825396826, 'recall_per_class': array([0., 1.]), 'recall_micro': 0.4365079365079365, 'recall_macro': 0.5, 'mcc_per_class': [0.0], 'mcc_overall': 0.0}\n",
      "*****\n",
      "No improvement for 4 epochs.\n",
      "Epoch 6, Train Loss: 0.000, Train metrics: {'f1_per_class': array([0.13975155, 0.59796807]), 'f1_micro': 0.4520276953511375, 'f1_macro': 0.36885981123060696, 'precision_per_class': array([0.59210526, 0.44064171]), 'precision_micro': 0.4520276953511375, 'precision_macro': 0.5163734871939206, 'recall_per_class': array([0.07922535, 0.93002257]), 'recall_micro': 0.4520276953511375, 'recall_macro': 0.5046239627380537, 'mcc_per_class': [0.017402344057820124], 'mcc_overall': 0.017402344057820124}\n",
      "            Val Loss:   0.000, Val F1:   {'f1_per_class': array([0.        , 0.60773481]), 'f1_micro': 0.4365079365079365, 'f1_macro': 0.30386740331491713, 'precision_per_class': array([0.        , 0.43650794]), 'precision_micro': 0.4365079365079365, 'precision_macro': 0.21825396825396826, 'recall_per_class': array([0., 1.]), 'recall_micro': 0.4365079365079365, 'recall_macro': 0.5, 'mcc_per_class': [0.0], 'mcc_overall': 0.0}\n",
      "*****\n",
      "No improvement for 5 epochs.\n",
      "Early stopping triggered after 5 epochs without improvement.\n",
      "\n",
      "Best model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " {'f1_per_class': array([0.        , 0.61202186]),\n",
       "  'f1_micro': 0.4409448818897638,\n",
       "  'f1_macro': 0.30601092896174864,\n",
       "  'precision_per_class': array([0.        , 0.44094488]),\n",
       "  'precision_micro': 0.4409448818897638,\n",
       "  'precision_macro': 0.2204724409448819,\n",
       "  'recall_per_class': array([0., 1.]),\n",
       "  'recall_micro': 0.4409448818897638,\n",
       "  'recall_macro': 0.5,\n",
       "  'mcc_per_class': [0.0],\n",
       "  'mcc_overall': 0.0})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCN no PCA\n",
    "trained_gcn_nopca = train(gcn_nopca, opt_gcn_nopca, train_loader_nopca, val_loader_nopca, model_arch=\"GCN\", epochs=100)\n",
    "print(\"\\nBest model:\")\n",
    "val_loss, val_metrics = evaluate(trained_gcn_nopca, test_loader_nopca, model_arch=\"GCN\")\n",
    "val_loss, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0b97d-5b0b-453e-8abd-414dff47acce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# GAT PCA\n",
    "trained_gat_pca = train(gat_pca, opt_gat_pca, train_loader_pca, val_loader_pca, model_arch=\"GAT\", scheduler=scheduler_gat_pca, epochs=100)\n",
    "print(\"\\nBest model:\")\n",
    "trained_gat_pca.eval()\n",
    "val_loss, val_metrics = evaluate(trained_gat_pca, test_loader_pca, model_arch=\"GAT\")\n",
    "val_loss, val_metrics\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031e0f3-5eff-45c0-b8fa-c573fb3aea60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GAT no PCA\n",
    "trained_gat_nopca = train(gat_nopca, opt_gat_nopca, train_loader_nopca, val_loader_nopca, model_arch=\"GAT\", epochs=100)\n",
    "print(\"\\nBest model:\")\n",
    "val_loss, val_metrics = evaluate(trained_gat_nopca, test_loader_nopca, model_arch=\"GAT\")\n",
    "val_loss, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679ef71-ce66-467c-aea3-e3cf8b2a3577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# GIN PCA\n",
    "trained_gin_pca = train(gin_pca, opt_gin_pca, train_loader_pca, val_loader_pca, model_arch=\"GIN\", scheduler=scheduler_gin_pca, epochs=100)\n",
    "print(\"\\nBest model:\")\n",
    "trained_gin_pca.eval()\n",
    "val_loss, val_metrics = evaluate(trained_gin_pca, test_loader_pca, model_arch=\"GIN\")\n",
    "val_loss, val_metrics\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063b65f-57fc-4af2-b40c-84ab01e132ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GIN no PCA\n",
    "trained_gin_nopca = train(gin_nopca, opt_gin_nopca, train_loader_nopca, val_loader_nopca, model_arch=\"GIN\", epochs=100)\n",
    "print(\"\\nBest model:\")\n",
    "val_loss, val_metrics = evaluate(trained_gin_nopca, test_loader_nopca, model_arch=\"GIN\")\n",
    "val_loss, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8792a8-f544-4624-a9f2-716101eab322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "torch.save(trained_gcn_nopca.state_dict(), '../res/trained_models/trained_gcn_nopca_noprotLM.pth')\n",
    "torch.save(trained_gat_nopca.state_dict(), '../res/trained_models/trained_gat_nopca_noprotLM.pth')\n",
    "torch.save(trained_gin_nopca.state_dict(), '../res/trained_models/trained_gin_nopca_noprotLM.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c1fd2-29c5-4352-b6b0-b33de5da7c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6901d5b-c65f-49ae-916d-1dc71e6ab332",
   "metadata": {},
   "source": [
    "### EGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d0b2c-a069-4619-a085-87e4b89d7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class E_GCL(nn.Module):\n",
    "    \"\"\"\n",
    "    E(n) Equivariant Convolutional Layer\n",
    "    re\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nf, output_nf, hidden_nf, edges_in_d=0, act_fn=nn.SiLU(), residual=True, attention=False, normalize=False, coords_agg='mean', tanh=False):\n",
    "        super(E_GCL, self).__init__()\n",
    "        input_edge = input_nf * 2\n",
    "        self.residual = residual\n",
    "        self.attention = attention\n",
    "        self.normalize = normalize\n",
    "        self.coords_agg = coords_agg\n",
    "        self.tanh = tanh\n",
    "        self.epsilon = 1e-8\n",
    "        edge_coords_nf = 1\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(input_edge + edge_coords_nf + edges_in_d, hidden_nf),\n",
    "            act_fn,\n",
    "            nn.Linear(hidden_nf, hidden_nf),\n",
    "            act_fn)\n",
    "\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_nf + input_nf, hidden_nf),\n",
    "            act_fn,\n",
    "            nn.Linear(hidden_nf, output_nf))\n",
    "\n",
    "        layer = nn.Linear(hidden_nf, 1, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
    "\n",
    "        coord_mlp = []\n",
    "        coord_mlp.append(nn.Linear(hidden_nf, hidden_nf))\n",
    "        coord_mlp.append(act_fn)\n",
    "        coord_mlp.append(layer)\n",
    "        if self.tanh:\n",
    "            coord_mlp.append(nn.Tanh())\n",
    "        self.coord_mlp = nn.Sequential(*coord_mlp)\n",
    "\n",
    "        if self.attention:\n",
    "            self.att_mlp = nn.Sequential(\n",
    "                nn.Linear(hidden_nf, 1),\n",
    "                nn.Sigmoid())\n",
    "\n",
    "    def edge_model(self, source, target, radial, edge_attr):\n",
    "        if edge_attr is None:  # Unused.\n",
    "            out = torch.cat([source, target, radial], dim=1)\n",
    "        else:\n",
    "            out = torch.cat([source, target, radial, edge_attr], dim=1)\n",
    "        out = self.edge_mlp(out)\n",
    "        if self.attention:\n",
    "            att_val = self.att_mlp(out)\n",
    "            out = out * att_val\n",
    "        return out\n",
    "\n",
    "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
    "        row, col = edge_index\n",
    "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0))\n",
    "        if node_attr is not None:\n",
    "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
    "        else:\n",
    "            agg = torch.cat([x, agg], dim=1)\n",
    "        out = self.node_mlp(agg)\n",
    "        if self.residual:\n",
    "            out = x + out\n",
    "        return out, agg\n",
    "\n",
    "    def coord_model(self, coord, edge_index, coord_diff, edge_feat):\n",
    "        row, col = edge_index\n",
    "        trans = coord_diff * self.coord_mlp(edge_feat)\n",
    "        if self.coords_agg == 'sum':\n",
    "            agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0))\n",
    "        elif self.coords_agg == 'mean':\n",
    "            agg = unsorted_segment_mean(trans, row, num_segments=coord.size(0))\n",
    "        else:\n",
    "            raise Exception('Wrong coords_agg parameter' % self.coords_agg)\n",
    "        coord += agg\n",
    "        return coord\n",
    "\n",
    "    def coord2radial(self, edge_index, coord):\n",
    "        row, col = edge_index\n",
    "        coord_diff = coord[row] - coord[col]\n",
    "        radial = torch.sum(coord_diff**2, 1).unsqueeze(1)\n",
    "\n",
    "        if self.normalize:\n",
    "            norm = torch.sqrt(radial).detach() + self.epsilon\n",
    "            coord_diff = coord_diff / norm\n",
    "\n",
    "        return radial, coord_diff\n",
    "\n",
    "    def forward(self, h, edge_index, coord, edge_attr=None, node_attr=None):\n",
    "        row, col = edge_index\n",
    "        radial, coord_diff = self.coord2radial(edge_index, coord)\n",
    "\n",
    "        edge_feat = self.edge_model(h[row], h[col], radial, edge_attr)\n",
    "        coord = self.coord_model(coord, edge_index, coord_diff, edge_feat)\n",
    "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
    "\n",
    "        return h, coord, edge_attr\n",
    "\n",
    "\n",
    "class EGNN(nn.Module):\n",
    "    def __init__(self, in_node_nf, hidden_nf, out_node_nf, in_edge_nf=0, device='cpu', act_fn=nn.SiLU(), n_layers=4, residual=True, attention=False, normalize=False, tanh=False):\n",
    "        '''\n",
    "\n",
    "        :param in_node_nf: Number of features for 'h' at the input\n",
    "        :param hidden_nf: Number of hidden features\n",
    "        :param out_node_nf: Number of features for 'h' at the output\n",
    "        :param in_edge_nf: Number of features for the edge features\n",
    "        :param device: Device (e.g. 'cpu', 'cuda:0',...)\n",
    "        :param act_fn: Non-linearity\n",
    "        :param n_layers: Number of layer for the EGNN\n",
    "        :param residual: Use residual connections, we recommend not changing this one\n",
    "        :param attention: Whether using attention or not\n",
    "        :param normalize: Normalizes the coordinates messages such that:\n",
    "                    instead of: x^{l+1}_i = x^{l}_i + Σ(x_i - x_j)phi_x(m_ij)\n",
    "                    we get:     x^{l+1}_i = x^{l}_i + Σ(x_i - x_j)phi_x(m_ij)/||x_i - x_j||\n",
    "                    We noticed it may help in the stability or generalization in some future works.\n",
    "                    We didn't use it in our paper.\n",
    "        :param tanh: Sets a tanh activation function at the output of phi_x(m_ij). I.e. it bounds the output of\n",
    "                        phi_x(m_ij) which definitely improves in stability but it may decrease in accuracy.\n",
    "                        We didn't use it in our paper.\n",
    "        '''\n",
    "\n",
    "        super(EGNN, self).__init__()\n",
    "        self.hidden_nf = hidden_nf\n",
    "        self.device = device\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding_in = nn.Linear(in_node_nf, self.hidden_nf)\n",
    "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
    "        for i in range(0, n_layers):\n",
    "            self.add_module(\"gcl_%d\" % i, E_GCL(self.hidden_nf, self.hidden_nf, self.hidden_nf, edges_in_d=in_edge_nf,\n",
    "                                                act_fn=act_fn, residual=residual, attention=attention,\n",
    "                                                normalize=normalize, tanh=tanh))\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, h, x, edges, edge_attr):\n",
    "        h = self.embedding_in(h)\n",
    "        for i in range(0, self.n_layers):\n",
    "            h, x, _ = self._modules[\"gcl_%d\" % i](h, edges, x, edge_attr=edge_attr)\n",
    "        h = self.embedding_out(h)\n",
    "        return h, x\n",
    "\n",
    "\n",
    "def unsorted_segment_sum(data, segment_ids, num_segments):\n",
    "    result_shape = (num_segments, data.size(1))\n",
    "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
    "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
    "    result.scatter_add_(0, segment_ids, data)\n",
    "    return result\n",
    "\n",
    "\n",
    "def unsorted_segment_mean(data, segment_ids, num_segments):\n",
    "    result_shape = (num_segments, data.size(1))\n",
    "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
    "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
    "    count = data.new_full(result_shape, 0)\n",
    "    result.scatter_add_(0, segment_ids, data)\n",
    "    count.scatter_add_(0, segment_ids, torch.ones_like(data))\n",
    "    return result / count.clamp(min=1)\n",
    "\n",
    "\n",
    "def get_edges(n_nodes):\n",
    "    rows, cols = [], []\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(n_nodes):\n",
    "            if i != j:\n",
    "                rows.append(i)\n",
    "                cols.append(j)\n",
    "\n",
    "    edges = [rows, cols]\n",
    "    return edges\n",
    "\n",
    "\n",
    "def get_edges_batch(n_nodes, batch_size):\n",
    "    edges = get_edges(n_nodes)\n",
    "    edge_attr = torch.ones(len(edges[0]) * batch_size, 1)\n",
    "    edges = [torch.LongTensor(edges[0]), torch.LongTensor(edges[1])]\n",
    "    if batch_size == 1:\n",
    "        return edges, edge_attr\n",
    "    elif batch_size > 1:\n",
    "        rows, cols = [], []\n",
    "        for i in range(batch_size):\n",
    "            rows.append(edges[0] + n_nodes * i)\n",
    "            cols.append(edges[1] + n_nodes * i)\n",
    "        edges = [torch.cat(rows), torch.cat(cols)]\n",
    "    return edges, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9419d-fc8e-466d-82a0-cf1a9d5e85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_add_pool\n",
    "\n",
    "class EGNN_Graph_Classifier(torch.nn.Module):\n",
    "    \"\"\"EGNN model for graph classification\"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out, dim_edge_attr, n_layers=4, n_layers_egnn=1, use_graph_feat=False, dim_graph_feature=0, dropout_p=0.5):\n",
    "        super(EGNN_Graph_Classifier, self).__init__()\n",
    "        self.args = (dim_in, dim_h, dim_out, dim_edge_attr, n_layers, n_layers_egnn, use_graph_feat, dim_graph_feature, dropout_p)\n",
    "        self.use_graph_feat = use_graph_feat\n",
    "        self.dropout_p = dropout_p\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # EGNN layers\n",
    "        self.egnn_layers = torch.nn.ModuleList([EGNN(in_node_nf=dim_in if i == 0 else dim_h // (2**i),\n",
    "                                                     hidden_nf=dim_h // (2**i),\n",
    "                                                     out_node_nf=dim_h // (2**(i+1)),\n",
    "                                                     in_edge_nf=dim_edge_attr, \n",
    "                                                     n_layers=n_layers_egnn)\n",
    "                                                for i in range(n_layers)])\n",
    "        \n",
    "        # Calculate the total dimension after pooling all EGNN layers\n",
    "        total_dim = sum([dim_h // (2**i) for i in range(n_layers)])  # Sum of pooled dimensions\n",
    "\n",
    "        if use_graph_feat:\n",
    "            total_dim += dim_graph_feature  # Adjust for graph-level features\n",
    "\n",
    "        # Linear layers for classification\n",
    "        self.lin1 = torch.nn.Linear(total_dim//2, dim_h // 4)\n",
    "        self.lin2 = torch.nn.Linear(dim_h // 4, dim_out)\n",
    "\n",
    "    def forward(self, h, edge_index, x, batch, graph_features=None):\n",
    "        # h: node features\n",
    "        # x: coordinates\n",
    "        h_list = []\n",
    "        \n",
    "        # Apply EGNN layers\n",
    "        for layer in self.egnn_layers:\n",
    "            h, x = layer(h, x, edge_index, edge_attr=None)\n",
    "            h_add = global_add_pool(h, batch)\n",
    "            h_list.append(h_add)\n",
    "        \n",
    "        # Concatenate pooled representations from all layers\n",
    "        h = torch.cat(h_list, dim=1)\n",
    "\n",
    "        # Concatenate graph-level features if applicable\n",
    "        if self.use_graph_feat and graph_features is not None:\n",
    "            graph_features = graph_features.view(h.shape[0], -1)\n",
    "            h = torch.cat([h, graph_features], dim=1)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        h = self.lin1(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        return h  # Return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ad541-f0d7-463f-a833-06dd431811f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training parameters\n",
    "input_dim_nopca = train_list_norm[0].x.shape[1]  # Adjust this based on your feature size\n",
    "input_dim_pca = train_list_norm_pca[0].x.shape[1]  # Adjust this based on your feature size\n",
    "hidden_dim = 128\n",
    "n_layers = 2\n",
    "n_layers_egnn = 2\n",
    "output_dim = 1  # Number of labels\n",
    "graph_features_dim = train_list_norm[0].u.shape[0]\n",
    "\n",
    "# define potential models\n",
    "egnn_pca   = EGNN_Graph_Classifier(input_dim_pca, hidden_dim, output_dim, dim_edge_attr=0, n_layers=n_layers, n_layers_egnn=n_layers_egnn, use_graph_feat=False, dropout_p=0.5).to(device) \n",
    "egnn_nopca   = EGNN_Graph_Classifier(input_dim_nopca, hidden_dim, output_dim, dim_edge_attr=0, n_layers=n_layers, n_layers_egnn=n_layers_egnn, use_graph_feat=False, dropout_p=0.5).to(device)\n",
    "\n",
    "\n",
    "LR = 5e-4\n",
    "WD = 5e-4\n",
    "# define optimizers\n",
    "opt_egnn_pca = torch.optim.AdamW(egnn_pca.parameters(), lr=LR, weight_decay=WD)\n",
    "opt_egnn_nopca = torch.optim.AdamW(egnn_nopca.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "# define schedulers\n",
    "scheduler_egnn_pca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_egnn_pca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "scheduler_egnn_nopca = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_egnn_nopca, mode='min', factor=0.1, patience=3, min_lr=1e-6)\n",
    "\n",
    "# define loss\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#criterion = FocalLoss()\n",
    "#criterion = FocalMCCLoss(lambda_mcc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e68e9-0a80-42f7-a51e-c638a0a66cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''# EGNN PCA\n",
    "trained_egnn_pca = train(egnn_pca, opt_egnn_pca, train_loader_pca, val_loader_pca, model_arch=\"EGNN\", scheduler=scheduler_egnn_pca, epochs=100)\n",
    "print(\"\\nBest model:\")\n",
    "trained_egnn_pca.eval()\n",
    "val_loss, val_metrics = evaluate(trained_egnn_pca, test_loader_pca, model_arch=\"EGNN\")\n",
    "val_loss, val_metrics\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85599fd4-ecf7-47ce-ae18-8d04a1f92f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EGNN no PCA\n",
    "trained_egnn_nopca = train(egnn_nopca, opt_egnn_nopca, train_loader_nopca, val_loader_nopca, model_arch=\"EGNN\", scheduler=scheduler_egnn_nopca, patience=5, y_index=2)\n",
    "print(\"\\nBest model:\")\n",
    "trained_egnn_nopca.eval()\n",
    "val_loss, val_metrics = evaluate(trained_egnn_nopca, test_loader_nopca, model_arch=\"EGNN\")\n",
    "val_loss, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99716f-da9d-4f94-a8ff-4447bb3f02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_egnn_nopca.state_dict(), '../res/trained_models/trained_egnn_nopca_noprotLM.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b80721-82fd-4a9a-b6a4-c27fbfd9e30d",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cb69a-d406-4d95-97cc-7013db8794ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read models\n",
    "\n",
    "trained_gcn_pca = GNN(\"GCN\", dim_in=291, dim_out=3 , dim_graph_feature=774, dim_h=128, n_layer=2, use_graph_feat=False).to(device)\n",
    "trained_gcn_pca.load_state_dict(torch.load('../res/trained_models/trained_gcn_nopca.pth'))\n",
    "trained_gcn_pca.eval()\n",
    "\n",
    "trained_gat_pca = GNN(\"GAT\", dim_in=291, dim_out=3 , dim_graph_feature=774, dim_h=128, n_layer=2, use_graph_feat=False, heads=1).to(device)\n",
    "trained_gat_pca.load_state_dict(torch.load('../res/trained_models/trained_gat_nopca.pth'))\n",
    "trained_gat_pca.eval()\n",
    "\n",
    "trained_gin_pca = GNN(\"GIN\", dim_in=291, dim_out=3 , dim_graph_feature=774, dim_h=128, n_layer=2, use_graph_feat=False).to(device)\n",
    "trained_gin_pca.load_state_dict(torch.load('../res/trained_models/trained_gin_nopca.pth'))\n",
    "trained_gin_pca.eval()\n",
    "\n",
    "trained_egnn_pca = EGNN_Graph_Classifier(dim_in=291, dim_h=128, dim_out=3, dim_edge_attr=0, n_layers=1, n_layers_egnn=2, use_graph_feat=False).to(device) \n",
    "trained_egnn_pca.load_state_dict(torch.load('../res/trained_models/trained_egnn_nopca.pth'))\n",
    "trained_egnn_pca.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04cef7-93f3-4548-ae76-860012e31ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN\n",
    "gcn_loss, gcn_test_metrics = evaluate(trained_gcn_nopca, test_loader_nopca, model_arch=\"GCN\")\n",
    "gcn_loss, gcn_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2ef46-6214-472b-98de-bafbae08cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT\n",
    "gat_loss, gat_test_metrics = evaluate(trained_gat_nopca, test_loader_nopca, model_arch=\"GAT\")\n",
    "gat_loss, gat_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c135c-1e4f-4b93-b2c8-7ff29145f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIN\n",
    "gin_loss, gin_test_metrics = evaluate(trained_gin_nopca, test_loader_nopca, model_arch=\"GIN\")\n",
    "gin_loss, gin_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b400b41-9138-4e3c-ab20-ced7d5623328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGNN\n",
    "egnn_loss, egnn_test_metrics = evaluate(trained_egnn_nopca, test_loader_nopca, model_arch=\"EGNN\")\n",
    "egnn_loss, egnn_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed7829-b563-4c21-aef9-94d2a92faf23",
   "metadata": {},
   "source": [
    "### extract predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf6cfa-8361-4bc9-a0e3-5208308c9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trained_egnn_nopca_noprotLM = EGNN_Graph_Classifier(dim_in=47, dim_h=64, dim_out=3, dim_edge_attr=0, n_layers=2, n_layers_egnn=2, use_graph_feat=False).to(device) \n",
    "trained_egnn_nopca_noprotLM.load_state_dict(torch.load('../res/trained_models/trained_egnn_nopca_noprotLM.pth'))\n",
    "trained_egnn_nopca_noprotLM.eval()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967b54d-5600-4186-a6fb-3d4b1709f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected model\n",
    "trained_gat_nopca_noprotLM = GNN(\"GAT\", dim_in=47, dim_out=3 , dim_graph_feature=774, dim_h=64, n_layer=2, use_graph_feat=False, heads=1).to(device)\n",
    "trained_gat_nopca_noprotLM.load_state_dict(torch.load('../res/trained_models/trained_gat_nopca_noprotLM.pth'))\n",
    "trained_gat_nopca_noprotLM.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39678b-746f-49fe-823a-f6aae6b46d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DN_graph_list = []\n",
    "LOF_graph_list = []\n",
    "GOF_graph_list = []\n",
    "\n",
    "for graph in (test_list_norm + val_list_norm + train_list_norm):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = trained_gat_nopca_noprotLM(x=graph.x.float(), edge_index=graph.edge_index, batch=graph.batch, graph_features=graph.u)\n",
    "        \n",
    "        #logits = trained_egnn_nopca_noprotLM(graph.x.float(), graph.edge_index, graph.coords.float(), graph.batch)\n",
    "\n",
    "    logits[logits>=0]=1\n",
    "    logits[logits<0]=0\n",
    "    \n",
    "    if torch.all(torch.tensor(graph.y) == logits):\n",
    "        \n",
    "        if graph.y == [1, 0, 0]:\n",
    "            DN_graph_list.append(graph)\n",
    "\n",
    "        if graph.y == [0, 1, 0]:\n",
    "            LOF_graph_list.append(graph)\n",
    "\n",
    "        if graph.y == [0, 0, 1]:\n",
    "            GOF_graph_list.append(graph)\n",
    "\n",
    "len(DN_graph_list), len(LOF_graph_list), len(GOF_graph_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847049ca-1a1c-4615-982e-664e10518ec1",
   "metadata": {},
   "source": [
    "### Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204cffa-808e-4d1d-a7c3-ee55f0e75590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer, CaptumExplainer\n",
    "\n",
    "'''\n",
    "explainer = Explainer(\n",
    "            model=trained_gin_nopca,\n",
    "            algorithm=GNNExplainer(epochs=250),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='attributes',\n",
    "            edge_mask_type=None,\n",
    "            model_config=dict(\n",
    "                mode='multiclass_classification',\n",
    "                task_level='graph',\n",
    "                return_type='log_probs',\n",
    "            ),\n",
    "        )\n",
    "'''\n",
    "explainer = Explainer(\n",
    "    model=trained_gat_nopca_noprotLM,\n",
    "    algorithm=CaptumExplainer('Saliency'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type=None,\n",
    "    threshold_config=dict(\n",
    "        threshold_type='topk',\n",
    "        value=20,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e838648-3259-4b31-9949-ed8950e347a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DN_feat_explain_score = torch.zeros(DN_graph_list[0].x.shape[1])\n",
    "LOF_feat_explain_score = torch.zeros(DN_graph_list[0].x.shape[1])\n",
    "GOF_feat_explain_score = torch.zeros(DN_graph_list[0].x.shape[1])\n",
    "\n",
    "for graph in DN_graph_list:\n",
    "    explanation = explainer(x=graph.x.float(), edge_index=graph.edge_index, batch=graph.batch, graph_features=graph.u)\n",
    "    DN_feat_explain_score += explanation.node_mask.sum(dim=0) \n",
    "\n",
    "for graph in LOF_graph_list:\n",
    "    explanation = explainer(x=graph.x.float(), edge_index=graph.edge_index, batch=graph.batch, graph_features=graph.u)\n",
    "    LOF_feat_explain_score += explanation.node_mask.sum(dim=0) \n",
    "\n",
    "for graph in GOF_graph_list:\n",
    "    explanation = explainer(x=graph.x.float(), edge_index=graph.edge_index, batch=graph.batch, graph_features=graph.u)\n",
    "    GOF_feat_explain_score += explanation.node_mask.sum(dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c1821-2dbb-4025-8dea-5bfbd188f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example lists (replace with your actual data)\n",
    "names = all_feature_names_filtered\n",
    "values = DN_feat_explain_score\n",
    "\n",
    "# Normalize the values by dividing by the maximum value\n",
    "max_value = max(values)\n",
    "normalized_values = [v / max_value for v in values]\n",
    "\n",
    "# Sort the data by the normalized values\n",
    "sorted_indices = np.argsort(normalized_values)\n",
    "sorted_names = [names[i] for i in sorted_indices]\n",
    "sorted_values = [normalized_values[i] for i in sorted_indices]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.barh(sorted_names, sorted_values, color='skyblue')\n",
    "plt.xlabel('Relative importance')\n",
    "plt.title('Dominant negative')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Ensure high quality plot for publication\n",
    "plt.tight_layout()\n",
    "plt.savefig('../res/plots/DN_featire_importance.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63985cec-d4d5-4409-a966-f3729b6ec72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example lists (replace with your actual data)\n",
    "names = all_feature_names_filtered\n",
    "values = LOF_feat_explain_score\n",
    "\n",
    "# Normalize the values by dividing by the maximum value\n",
    "max_value = max(values)\n",
    "normalized_values = [v / max_value for v in values]\n",
    "\n",
    "# Sort the data by the normalized values\n",
    "sorted_indices = np.argsort(normalized_values)\n",
    "sorted_names = [names[i] for i in sorted_indices]\n",
    "sorted_values = [normalized_values[i] for i in sorted_indices]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.barh(sorted_names, sorted_values, color='skyblue')\n",
    "plt.xlabel('Relative importance')\n",
    "plt.title('Loss of function')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Ensure high quality plot for publication\n",
    "plt.tight_layout()\n",
    "plt.savefig('../res/plots/LOF_featire_importance.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e7a36-7027-47a7-bbc7-ce7316165321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example lists (replace with your actual data)\n",
    "names = all_feature_names_filtered\n",
    "values = GOF_feat_explain_score\n",
    "\n",
    "# Normalize the values by dividing by the maximum value\n",
    "max_value = max(values)\n",
    "normalized_values = [v / max_value for v in values]\n",
    "\n",
    "# Sort the data by the normalized values\n",
    "sorted_indices = np.argsort(normalized_values)\n",
    "sorted_names = [names[i] for i in sorted_indices]\n",
    "sorted_values = [normalized_values[i] for i in sorted_indices]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.barh(sorted_names, sorted_values, color='skyblue')\n",
    "plt.xlabel('Relative importance')\n",
    "plt.title('Gain of function')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Ensure high quality plot for publication\n",
    "plt.tight_layout()\n",
    "plt.savefig('../res/plots/GOF_featire_importance.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434be6a-5b69-463d-8adf-68d2965bd498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
